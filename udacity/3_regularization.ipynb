{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 931.474609\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.6%\n",
      "Minibatch loss at step 500: 1.179510\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1000: 1.229837\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1500: 1.412376\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 2000: 1.080016\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 2500: 1.226054\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 3000: 1.205091\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 3500: 1.289847\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 4000: 1.472557\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 4500: 1.198334\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 5000: 1.475516\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 5500: 1.190779\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 6000: 1.137421\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 6500: 1.256023\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 7000: 1.307621\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 7500: 1.372643\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 8000: 1.266176\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 8500: 1.418868\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 9000: 1.202076\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 9500: 1.297863\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 10000: 1.276278\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.3%\n",
      "Test accuracy: 85.2%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "lambda_ = .3\n",
    "lr = .125\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)\n",
    "        + lambda_ * tf.nn.l2_loss(weights) \n",
    "        + lambda_ * tf.nn.l2_loss(biases)\n",
    "        )\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "    \n",
    "    \n",
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4704.526367\n",
      "Minibatch accuracy: 10.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 2320.164062\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 30.1%\n",
      "Minibatch loss at step 2000: 1107.817993\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 40.7%\n",
      "Minibatch loss at step 3000: 364.240173\n",
      "Minibatch accuracy: 57.3%\n",
      "Validation accuracy: 59.0%\n",
      "Minibatch loss at step 4000: 83.693680\n",
      "Minibatch accuracy: 70.8%\n",
      "Validation accuracy: 70.9%\n",
      "Minibatch loss at step 5000: 16.179203\n",
      "Minibatch accuracy: 77.1%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 6000: 3.132547\n",
      "Minibatch accuracy: 83.3%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 7000: 0.983776\n",
      "Minibatch accuracy: 85.4%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 8000: 0.642909\n",
      "Minibatch accuracy: 85.4%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 9000: 0.744519\n",
      "Minibatch accuracy: 80.2%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 10000: 0.525013\n",
      "Minibatch accuracy: 89.6%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 11000: 0.668530\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 12000: 0.669513\n",
      "Minibatch accuracy: 85.4%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 13000: 0.450438\n",
      "Minibatch accuracy: 89.6%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 14000: 0.740768\n",
      "Minibatch accuracy: 85.4%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 15000: 0.578744\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 91.5%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 96\n",
    "h0 = 1024 \n",
    "h1 = 32\n",
    "lambda_ = 0.005\n",
    "lr = .001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    biases0 = tf.Variable(tf.zeros([h0]))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    biases1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights0) + biases0)\n",
    "    s1 = tf.nn.relu(tf.matmul(s0, weights1) + biases1)\n",
    "    logits = tf.matmul(s1, weights2) + biases2\n",
    "\n",
    "    # reg = tf.nn.l2_loss(weights0) + tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2)\n",
    "    reg = tf.reduce_sum(tf.square(weights0)) + tf.reduce_sum(tf.square(weights1)) + tf.reduce_sum(tf.square(weights1))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "    \n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v1, weights2) + biases2)\n",
    "    \n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t1, weights2) + biases2)\n",
    "    \n",
    "    t_pred = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t_pred = tf.nn.relu(tf.matmul(t_pred, weights1) + biases1)\n",
    "    t_pred = tf.matmul(t_pred, weights2) + biases2\n",
    "    # t_pred = tf.matmul(t_pred, weights1) + biases1\n",
    "    test_prediction = tf.nn.softmax(t_pred)\n",
    "        \n",
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2068.638428\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 12.2%\n",
      "Minibatch loss at step 1000: 722.624268\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 21.5%\n",
      "Minibatch loss at step 2000: 562.912170\n",
      "Minibatch accuracy: 33.3%\n",
      "Validation accuracy: 26.4%\n",
      "Minibatch loss at step 3000: 371.479340\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 39.6%\n",
      "Minibatch loss at step 4000: 197.814926\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 44.5%\n",
      "Minibatch loss at step 5000: 85.263542\n",
      "Minibatch accuracy: 51.0%\n",
      "Validation accuracy: 54.9%\n",
      "Minibatch loss at step 6000: 32.535183\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 66.1%\n",
      "Minibatch loss at step 7000: 12.401726\n",
      "Minibatch accuracy: 76.0%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 8000: 4.871196\n",
      "Minibatch accuracy: 82.3%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 9000: 2.135779\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.1%\n",
      "Minibatch loss at step 10000: 0.845630\n",
      "Minibatch accuracy: 89.6%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 11000: 0.766105\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 12000: 0.654343\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 13000: 0.491101\n",
      "Minibatch accuracy: 89.6%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 14000: 0.675095\n",
      "Minibatch accuracy: 86.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 15000: 0.564142\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.6%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 96\n",
    "h0 = 1024 \n",
    "h1 = 32\n",
    "lambda_ = 0.0025\n",
    "lr = .001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    biases0 = tf.Variable(tf.zeros([h0]))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    biases1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights0) + biases0)\n",
    "    s1 = tf.nn.relu(tf.matmul(s0, weights1) + biases1)\n",
    "    logits = tf.matmul(s1, weights2) + biases2\n",
    "\n",
    "    reg = tf.nn.l2_loss(weights0) + tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2)\n",
    "    # reg = tf.reduce_sum(tf.square(weights0)) + tf.reduce_sum(tf.square(weights1)) + tf.reduce_sum(tf.square(weights1))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "    \n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v1, weights2) + biases2)\n",
    "    \n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t1, weights2) + biases2)\n",
    "    \n",
    "    t_pred = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t_pred = tf.nn.relu(tf.matmul(t_pred, weights1) + biases1)\n",
    "    t_pred = tf.matmul(t_pred, weights2) + biases2\n",
    "    # t_pred = tf.matmul(t_pred, weights1) + biases1\n",
    "    test_prediction = tf.nn.softmax(t_pred)\n",
    "        \n",
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 824.395447\n",
      "Minibatch accuracy: 10.4%\n",
      "Validation accuracy: 15.1%\n",
      "Minibatch loss at step 1000: 0.019850\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 2000: 0.013736\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 3000: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 4000: 0.004536\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 5000: 0.002494\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 6000: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 7000: 0.000825\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 8000: 0.000494\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 9000: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.1%\n",
      "Minibatch loss at step 10000: 0.000186\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.0%\n",
      "Minibatch loss at step 11000: 0.000116\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.0%\n",
      "Minibatch loss at step 12000: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 44.0%\n",
      "Test accuracy: 48.1%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 96\n",
    "h0 = 1024 \n",
    "h1 = 32\n",
    "lambda_ = 0.00\n",
    "lr = .001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    biases0 = tf.Variable(tf.zeros([h0]))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    biases1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights0) + biases0)\n",
    "    s1 = tf.nn.relu(tf.matmul(s0, weights1) + biases1)\n",
    "    logits = tf.matmul(s1, weights2) + biases2\n",
    "\n",
    "    reg = tf.nn.l2_loss(weights0) + tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2)\n",
    "    # reg = tf.reduce_sum(tf.square(weights0)) + tf.reduce_sum(tf.square(weights1)) + tf.reduce_sum(tf.square(weights1))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "    \n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v1, weights2) + biases2)\n",
    "    \n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t1, weights2) + biases2)\n",
    "    \n",
    "    t_pred = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t_pred = tf.nn.relu(tf.matmul(t_pred, weights1) + biases1)\n",
    "    t_pred = tf.matmul(t_pred, weights2) + biases2\n",
    "    # t_pred = tf.matmul(t_pred, weights1) + biases1\n",
    "    test_prediction = tf.nn.softmax(t_pred)\n",
    "        \n",
    "num_steps = 12001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "    # offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1967.771606\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.1%\n",
      "Minibatch loss at step 1000: 4.915576\n",
      "Minibatch accuracy: 19.8%\n",
      "Validation accuracy: 17.2%\n",
      "Minibatch loss at step 2000: 1.868286\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 3000: 1.647395\n",
      "Minibatch accuracy: 35.4%\n",
      "Validation accuracy: 24.2%\n",
      "Minibatch loss at step 4000: 1.838254\n",
      "Minibatch accuracy: 36.5%\n",
      "Validation accuracy: 29.7%\n",
      "Minibatch loss at step 5000: 1.494194\n",
      "Minibatch accuracy: 40.6%\n",
      "Validation accuracy: 33.7%\n",
      "Minibatch loss at step 6000: 1.324174\n",
      "Minibatch accuracy: 47.9%\n",
      "Validation accuracy: 41.7%\n",
      "Minibatch loss at step 7000: 1.437298\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 8000: 1.307086\n",
      "Minibatch accuracy: 49.0%\n",
      "Validation accuracy: 47.0%\n",
      "Minibatch loss at step 9000: 1.470837\n",
      "Minibatch accuracy: 45.8%\n",
      "Validation accuracy: 47.0%\n",
      "Minibatch loss at step 10000: 1.345255\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 48.2%\n",
      "Minibatch loss at step 11000: 1.176030\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 49.7%\n",
      "Minibatch loss at step 12000: 1.130352\n",
      "Minibatch accuracy: 52.1%\n",
      "Validation accuracy: 50.9%\n",
      "Minibatch loss at step 13000: 1.180512\n",
      "Minibatch accuracy: 49.0%\n",
      "Validation accuracy: 49.7%\n",
      "Minibatch loss at step 14000: 0.784982\n",
      "Minibatch accuracy: 63.5%\n",
      "Validation accuracy: 53.9%\n",
      "Minibatch loss at step 15000: 1.026312\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 54.1%\n",
      "Minibatch loss at step 16000: 0.962711\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 55.9%\n",
      "Minibatch loss at step 17000: 0.994804\n",
      "Minibatch accuracy: 58.3%\n",
      "Validation accuracy: 56.9%\n",
      "Minibatch loss at step 18000: 1.204160\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 53.7%\n",
      "Minibatch loss at step 19000: 0.944752\n",
      "Minibatch accuracy: 63.5%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 20000: 0.899664\n",
      "Minibatch accuracy: 64.6%\n",
      "Validation accuracy: 58.0%\n",
      "Test accuracy: 64.9%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 96\n",
    "h0 = 1024 \n",
    "h1 = 32\n",
    "lambda_ = 0.00\n",
    "lr = .001\n",
    "keep_prob = .625\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    biases0 = tf.Variable(tf.zeros([h0]))\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    biases1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([h1, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, weights0) + biases0), keep_prob)\n",
    "    s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, weights1) + biases1), keep_prob)\n",
    "    logits = tf.matmul(s1, weights2) + biases2\n",
    "\n",
    "    reg = tf.nn.l2_loss(weights0) + tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2)\n",
    "    # reg = tf.reduce_sum(tf.square(weights0)) + tf.reduce_sum(tf.square(weights1)) + tf.reduce_sum(tf.square(weights1))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "    \n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights0) + biases0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v1, weights2) + biases2)\n",
    "    \n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t1, weights2) + biases2)\n",
    "    \n",
    "    t_pred = tf.nn.relu(tf.matmul(tf_test_dataset, weights0) + biases0)\n",
    "    t_pred = tf.nn.relu(tf.matmul(t_pred, weights1) + biases1)\n",
    "    t_pred = tf.matmul(t_pred, weights2) + biases2\n",
    "    # t_pred = tf.matmul(t_pred, weights1) + biases1\n",
    "    test_prediction = tf.nn.softmax(t_pred)\n",
    "        \n",
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "    # offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 19930.998047\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 2000: 620.792725\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 4000: 168.996170\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 6000: 104.573509\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 8000: 52.844090\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 10000: 24.543062\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 69.1%\n",
      "Minibatch loss at step 12000: 14.801310\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 63.9%\n",
      "Minibatch loss at step 14000: 7.372912\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 16000: 2.480627\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 57.1%\n",
      "Minibatch loss at step 18000: 3.049649\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 20000: 2.842341\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 60.1%\n",
      "Minibatch loss at step 22000: 2.144602\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 62.6%\n",
      "Minibatch loss at step 24000: 2.285338\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 65.7%\n",
      "Minibatch loss at step 26000: 2.257201\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 67.8%\n",
      "Minibatch loss at step 28000: 2.746567\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 30000: 1.819721\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 70.3%\n",
      "Minibatch loss at step 32000: 1.771166\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 34000: 1.935265\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 36000: 2.056959\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 38000: 1.867115\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 40000: 1.628083\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 42000: 1.683332\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 44000: 1.632215\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 46000: 1.253013\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 48000: 1.403634\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 50000: 1.449454\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.0%\n",
      "Test accuracy: 86.7%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "h0 = 256\n",
    "h1 = 256\n",
    "h2 = 256\n",
    "lambda_ = 1e-5\n",
    "lr = .001\n",
    "keep_prob = .85\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    w0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    b0 = tf.Variable(tf.zeros([h0]))\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    b1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([h1, h2]))\n",
    "    b2 = tf.Variable(tf.zeros([h2]))\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2, num_labels]))\n",
    "    b3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0), keep_prob)\n",
    "    s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, w1) + b1), keep_prob)\n",
    "    s2 = tf.nn.relu(tf.matmul(s1, w2) + b2)\n",
    "    logits = tf.matmul(s2, w3) + b3\n",
    "\n",
    "    reg = tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)\n",
    "    # reg = tf.reduce_sum(tf.square(w0)) + tf.reduce_sum(tf.square(w1)) + tf.reduce_sum(tf.square(w1))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "\n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, w0) + b0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, w1) + b1)\n",
    "    v2 = tf.nn.relu(tf.matmul(v1, w2) + b2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v2, w3) + b3)\n",
    "\n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, w0) + b0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, w1) + b1)\n",
    "    t2 = tf.nn.relu(tf.matmul(t1, w2) + b2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t2, w3) + b3)\n",
    "\n",
    "num_steps = 50001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        # offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 2000 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Avg Minibatch loss for epoch 0: 3761.436169\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 77.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 1: 1105.405648\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 77.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 2: 632.923827\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 76.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 3: 393.026527\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 75.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 4: 248.010304\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 72.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 5: 147.903750\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 68.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 6: 90.266291\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 61.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 7: 57.327172\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 57.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 8: 38.531971\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 53.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 9: 27.459044\n",
      "Minibatch accuracy: 39.1%\n",
      "Validation accuracy: 49.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 10: 20.133840\n",
      "Minibatch accuracy: 40.6%\n",
      "Validation accuracy: 46.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 11: 15.675677\n",
      "Minibatch accuracy: 42.2%\n",
      "Validation accuracy: 44.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 12: 12.421778\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 42.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 13: 10.141887\n",
      "Minibatch accuracy: 29.7%\n",
      "Validation accuracy: 41.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 14: 8.444100\n",
      "Minibatch accuracy: 30.5%\n",
      "Validation accuracy: 40.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 15: 7.286376\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 39.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 16: 6.482876\n",
      "Minibatch accuracy: 35.2%\n",
      "Validation accuracy: 38.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 17: 5.708975\n",
      "Minibatch accuracy: 29.7%\n",
      "Validation accuracy: 38.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 18: 5.219643\n",
      "Minibatch accuracy: 30.5%\n",
      "Validation accuracy: 37.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 19: 4.758779\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 37.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 20: 4.412750\n",
      "Minibatch accuracy: 30.5%\n",
      "Validation accuracy: 36.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 21: 4.115444\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 37.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 22: 3.886933\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 38.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 23: 3.696784\n",
      "Minibatch accuracy: 27.3%\n",
      "Validation accuracy: 38.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 24: 3.495490\n",
      "Minibatch accuracy: 27.3%\n",
      "Validation accuracy: 39.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 25: 3.370626\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 40.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 26: 3.273663\n",
      "Minibatch accuracy: 25.8%\n",
      "Validation accuracy: 40.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 27: 3.175868\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 42.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 28: 3.107346\n",
      "Minibatch accuracy: 39.1%\n",
      "Validation accuracy: 44.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 29: 3.027849\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 44.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 30: 2.946386\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 47.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 31: 2.884846\n",
      "Minibatch accuracy: 38.3%\n",
      "Validation accuracy: 48.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 32: 2.806416\n",
      "Minibatch accuracy: 40.6%\n",
      "Validation accuracy: 50.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 33: 2.745460\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 51.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 34: 2.690783\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 54.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 35: 2.628739\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 55.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 36: 2.565035\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 56.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 37: 2.502493\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 58.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 38: 2.435368\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 59.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 39: 2.372908\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 61.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 40: 2.320040\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 62.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 41: 2.261591\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 64.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 42: 2.198539\n",
      "Minibatch accuracy: 53.9%\n",
      "Validation accuracy: 65.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 43: 2.134343\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 67.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 44: 2.083078\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 68.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 45: 2.023461\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 69.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 46: 1.975577\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 70.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 47: 1.928382\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 71.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 48: 1.863532\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 72.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 49: 1.819610\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 73.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 50: 1.774273\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 73.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 51: 1.731128\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 74.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 52: 1.686691\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 75.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 53: 1.638160\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 76.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 54: 1.602499\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 76.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 55: 1.560972\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 56: 1.531053\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 78.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 57: 1.495514\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 58: 1.465185\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 59: 1.429069\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 60: 1.399098\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 61: 1.369973\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 62: 1.339936\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 63: 1.307996\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 64: 1.282180\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 65: 1.257533\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 66: 1.233080\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 67: 1.204004\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 68: 1.180726\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 69: 1.154948\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 70: 1.129384\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 71: 1.108404\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 82.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 72: 1.084715\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 73: 1.062013\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 74: 1.033511\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 75: 1.006804\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 83.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 76: 0.982396\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 84.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 77: 0.960882\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 84.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 78: 0.939477\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 79: 0.920167\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 80: 0.900181\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 81: 0.880687\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 82: 0.861895\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 83: 0.842557\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 84: 0.825625\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 85: 0.807119\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 86: 0.790913\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 87: 0.774725\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 88: 0.757989\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 89: 0.742855\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 90: 0.729613\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 91: 0.714709\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 92: 0.701121\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 93: 0.688172\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 94: 0.674729\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 95: 0.661883\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 96: 0.650237\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 97: 0.637639\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 98: 0.628756\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 99: 0.618295\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 100: 0.607117\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 101: 0.597529\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 102: 0.588187\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 103: 0.579086\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 104: 0.569691\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 105: 0.562179\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 106: 0.552494\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 107: 0.544386\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 108: 0.538630\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 109: 0.530483\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 110: 0.525425\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 111: 0.517898\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 112: 0.509951\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 113: 0.503313\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 114: 0.496825\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 115: 0.490981\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 116: 0.484501\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 117: 0.479652\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 118: 0.476284\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 119: 0.468616\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 120: 0.464883\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 121: 0.460528\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 122: 0.454157\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 123: 0.450922\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 124: 0.445954\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "\n",
      "Avg Minibatch loss for epoch 125: 0.441671\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.6%\n",
      "\n",
      "Avg Minibatch loss for epoch 126: 0.436665\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 127: 0.434959\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 128: 0.428357\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 129: 0.426274\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 130: 0.422290\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 131: 0.419616\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.7%\n",
      "\n",
      "Avg Minibatch loss for epoch 132: 0.415814\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.8%\n",
      "\n",
      "Avg Minibatch loss for epoch 133: 0.411888\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 134: 0.407404\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 135: 0.404666\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 136: 0.401657\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.9%\n",
      "\n",
      "Avg Minibatch loss for epoch 137: 0.399618\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 138: 0.395793\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 139: 0.393970\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 140: 0.389863\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 141: 0.388996\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 142: 0.385291\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 143: 0.382874\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 144: 0.377972\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 145: 0.375917\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 146: 0.374021\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 147: 0.371978\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 148: 0.369236\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 149: 0.368191\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 150: 0.365123\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 151: 0.363120\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 152: 0.361311\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 153: 0.360992\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.0%\n",
      "\n",
      "Avg Minibatch loss for epoch 154: 0.358143\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 155: 0.355227\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 156: 0.353814\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 157: 0.351129\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 158: 0.351261\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 159: 0.349149\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 160: 0.347603\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 161: 0.344505\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 162: 0.344120\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 163: 0.341661\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 164: 0.340827\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 165: 0.338482\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 166: 0.336700\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 167: 0.333261\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 168: 0.334311\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 169: 0.332340\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 170: 0.331598\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Avg Minibatch loss for epoch 171: 0.328813\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.2%\n",
      "\n",
      "Avg Minibatch loss for epoch 172: 0.329796\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.1%\n",
      "\n",
      "Avg Minibatch loss for epoch 173: 0.326496\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.4%\n",
      "\n",
      "Avg Minibatch loss for epoch 174: 0.324595\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "\n",
      "Test accuracy: 95.9%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "h0 = 256\n",
    "h1 = 256\n",
    "h2 = 256\n",
    "lambda_ = 1e-5\n",
    "lr = .0005\n",
    "keep_prob = .675\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    w0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    b0 = tf.Variable(tf.zeros([h0]))\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    b1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([h1, h2]))\n",
    "    b2 = tf.Variable(tf.zeros([h2]))\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2, num_labels]))\n",
    "    b3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0), keep_prob)\n",
    "    s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, w1) + b1), keep_prob)\n",
    "    s2 = tf.nn.relu(tf.matmul(s1, w2) + b2)\n",
    "    logits = tf.matmul(s2, w3) + b3\n",
    "\n",
    "    reg = tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)\n",
    "    # reg = tf.reduce_sum(tf.square(w0)) + tf.reduce_sum(tf.square(w1)) + tf.reduce_sum(tf.square(w1))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "\n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, w0) + b0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, w1) + b1)\n",
    "    v2 = tf.nn.relu(tf.matmul(v1, w2) + b2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v2, w3) + b3)\n",
    "\n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, w0) + b0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, w1) + b1)\n",
    "    t2 = tf.nn.relu(tf.matmul(t1, w2) + b2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t2, w3) + b3)\n",
    "\n",
    "batches = np.ceil(float(train_labels.shape[0]) / batch_size)\n",
    "num_epochs = 175\n",
    "num_steps = int(np.ceil(float(train_labels.shape[0]) / batch_size))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for epoch in range(num_epochs):\n",
    "        l_mean = 0\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            # offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            l_mean += l\n",
    "\n",
    "        if (epoch % 1 == 0):\n",
    "            print(\"Avg Minibatch loss for epoch %d: %f\" % (epoch, l_mean / num_steps))\n",
    "            # print(\" Minibatch loss at end of epoch %d: %f\" % (epoch, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\\n\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Avg Minibatch loss for epoch 0: 2886.379087\n",
      " Minibatch accuracy: 54.7%\n",
      "  ***   Training set accuracy: 77.80% ***\n",
      "  *** Validation set accuracy: 77.43% ***\n",
      "Avg Minibatch loss for epoch 1: 736.311754\n",
      " Minibatch accuracy: 59.4%\n",
      "Avg Minibatch loss for epoch 2: 358.629818\n",
      " Minibatch accuracy: 62.5%\n",
      "Avg Minibatch loss for epoch 3: 174.180594\n",
      " Minibatch accuracy: 53.1%\n",
      "Avg Minibatch loss for epoch 4: 83.722366\n",
      " Minibatch accuracy: 48.4%\n",
      "Avg Minibatch loss for epoch 5: 45.430048\n",
      " Minibatch accuracy: 45.3%\n",
      "  ***   Training set accuracy: 55.45% ***\n",
      "  *** Validation set accuracy: 55.21% ***\n",
      "Avg Minibatch loss for epoch 6: 28.766584\n",
      " Minibatch accuracy: 37.5%\n",
      "Avg Minibatch loss for epoch 7: 20.805520\n",
      " Minibatch accuracy: 29.7%\n",
      "Avg Minibatch loss for epoch 8: 16.216207\n",
      " Minibatch accuracy: 31.2%\n",
      "Avg Minibatch loss for epoch 9: 13.543785\n",
      " Minibatch accuracy: 35.9%\n",
      "Avg Minibatch loss for epoch 10: 11.727413\n",
      " Minibatch accuracy: 35.9%\n",
      "  ***   Training set accuracy: 40.28% ***\n",
      "  *** Validation set accuracy: 39.69% ***\n",
      "Avg Minibatch loss for epoch 11: 10.599947\n",
      " Minibatch accuracy: 28.1%\n",
      "Avg Minibatch loss for epoch 12: 9.744868\n",
      " Minibatch accuracy: 29.7%\n",
      "Avg Minibatch loss for epoch 13: 9.107700\n",
      " Minibatch accuracy: 35.9%\n",
      "Avg Minibatch loss for epoch 14: 8.583165\n",
      " Minibatch accuracy: 32.8%\n",
      "Avg Minibatch loss for epoch 15: 8.158097\n",
      " Minibatch accuracy: 34.4%\n",
      "  ***   Training set accuracy: 42.93% ***\n",
      "  *** Validation set accuracy: 42.63% ***\n",
      "Avg Minibatch loss for epoch 16: 7.763007\n",
      " Minibatch accuracy: 31.2%\n",
      "Avg Minibatch loss for epoch 17: 7.384237\n",
      " Minibatch accuracy: 40.6%\n",
      "Avg Minibatch loss for epoch 18: 7.014268\n",
      " Minibatch accuracy: 40.6%\n",
      "Avg Minibatch loss for epoch 19: 6.660506\n",
      " Minibatch accuracy: 39.1%\n",
      "Avg Minibatch loss for epoch 20: 6.306482\n",
      " Minibatch accuracy: 35.9%\n",
      "  ***   Training set accuracy: 54.18% ***\n",
      "  *** Validation set accuracy: 53.56% ***\n",
      "Avg Minibatch loss for epoch 21: 5.934962\n",
      " Minibatch accuracy: 45.3%\n",
      "Avg Minibatch loss for epoch 22: 5.556182\n",
      " Minibatch accuracy: 50.0%\n",
      "Avg Minibatch loss for epoch 23: 5.186158\n",
      " Minibatch accuracy: 48.4%\n",
      "Avg Minibatch loss for epoch 24: 4.798848\n",
      " Minibatch accuracy: 56.2%\n",
      "Avg Minibatch loss for epoch 25: 4.416582\n",
      " Minibatch accuracy: 56.2%\n",
      "  ***   Training set accuracy: 68.93% ***\n",
      "  *** Validation set accuracy: 68.48% ***\n",
      "Avg Minibatch loss for epoch 26: 4.043437\n",
      " Minibatch accuracy: 59.4%\n",
      "Avg Minibatch loss for epoch 27: 3.675560\n",
      " Minibatch accuracy: 64.1%\n",
      "Avg Minibatch loss for epoch 28: 3.339372\n",
      " Minibatch accuracy: 67.2%\n",
      "Avg Minibatch loss for epoch 29: 2.996077\n",
      " Minibatch accuracy: 60.9%\n",
      "Avg Minibatch loss for epoch 30: 2.672326\n",
      " Minibatch accuracy: 68.8%\n",
      "  ***   Training set accuracy: 79.72% ***\n",
      "  *** Validation set accuracy: 79.29% ***\n",
      "Avg Minibatch loss for epoch 31: 2.370600\n",
      " Minibatch accuracy: 68.8%\n",
      "Avg Minibatch loss for epoch 32: 2.078722\n",
      " Minibatch accuracy: 70.3%\n",
      "Avg Minibatch loss for epoch 33: 1.817723\n",
      " Minibatch accuracy: 70.3%\n",
      "Avg Minibatch loss for epoch 34: 1.582907\n",
      " Minibatch accuracy: 73.4%\n",
      "Avg Minibatch loss for epoch 35: 1.389381\n",
      " Minibatch accuracy: 75.0%\n",
      "  ***   Training set accuracy: 85.38% ***\n",
      "  *** Validation set accuracy: 84.52% ***\n",
      "Avg Minibatch loss for epoch 36: 1.227817\n",
      " Minibatch accuracy: 76.6%\n",
      "Avg Minibatch loss for epoch 37: 1.096152\n",
      " Minibatch accuracy: 78.1%\n",
      "Avg Minibatch loss for epoch 38: 0.986050\n",
      " Minibatch accuracy: 75.0%\n",
      "Avg Minibatch loss for epoch 39: 0.893367\n",
      " Minibatch accuracy: 78.1%\n",
      "Avg Minibatch loss for epoch 40: 0.817475\n",
      " Minibatch accuracy: 78.1%\n",
      "  ***   Training set accuracy: 88.82% ***\n",
      "  *** Validation set accuracy: 87.59% ***\n",
      "Avg Minibatch loss for epoch 41: 0.755732\n",
      " Minibatch accuracy: 79.7%\n",
      "Avg Minibatch loss for epoch 42: 0.701772\n",
      " Minibatch accuracy: 81.2%\n",
      "Avg Minibatch loss for epoch 43: 0.658068\n",
      " Minibatch accuracy: 75.0%\n",
      "Avg Minibatch loss for epoch 44: 0.621558\n",
      " Minibatch accuracy: 78.1%\n",
      "Avg Minibatch loss for epoch 45: 0.589617\n",
      " Minibatch accuracy: 82.8%\n",
      "  ***   Training set accuracy: 90.51% ***\n",
      "  *** Validation set accuracy: 88.85% ***\n",
      "Avg Minibatch loss for epoch 46: 0.561247\n",
      " Minibatch accuracy: 81.2%\n",
      "Avg Minibatch loss for epoch 47: 0.538538\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 48: 0.518422\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 49: 0.501588\n",
      " Minibatch accuracy: 82.8%\n",
      "Avg Minibatch loss for epoch 50: 0.486344\n",
      " Minibatch accuracy: 82.8%\n",
      "  ***   Training set accuracy: 91.42% ***\n",
      "  *** Validation set accuracy: 89.51% ***\n",
      "Avg Minibatch loss for epoch 51: 0.470976\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 52: 0.461334\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 53: 0.451910\n",
      " Minibatch accuracy: 81.2%\n",
      "Avg Minibatch loss for epoch 54: 0.441093\n",
      " Minibatch accuracy: 82.8%\n",
      "Avg Minibatch loss for epoch 55: 0.431756\n",
      " Minibatch accuracy: 87.5%\n",
      "  ***   Training set accuracy: 92.11% ***\n",
      "  *** Validation set accuracy: 89.87% ***\n",
      "Avg Minibatch loss for epoch 56: 0.425030\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 57: 0.417706\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 58: 0.411090\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 59: 0.407441\n",
      " Minibatch accuracy: 82.8%\n",
      "Avg Minibatch loss for epoch 60: 0.402460\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 92.50% ***\n",
      "  *** Validation set accuracy: 90.22% ***\n",
      "Avg Minibatch loss for epoch 61: 0.397353\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 62: 0.394380\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 63: 0.389965\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 64: 0.388404\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 65: 0.384312\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 92.89% ***\n",
      "  *** Validation set accuracy: 90.22% ***\n",
      "Avg Minibatch loss for epoch 66: 0.381404\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 67: 0.378305\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 68: 0.377867\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 69: 0.374535\n",
      " Minibatch accuracy: 84.4%\n",
      "Avg Minibatch loss for epoch 70: 0.372589\n",
      " Minibatch accuracy: 87.5%\n",
      "  ***   Training set accuracy: 93.07% ***\n",
      "  *** Validation set accuracy: 90.31% ***\n",
      "Avg Minibatch loss for epoch 71: 0.370445\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 72: 0.367474\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 73: 0.368221\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 74: 0.366073\n",
      " Minibatch accuracy: 84.4%\n",
      "Avg Minibatch loss for epoch 75: 0.365104\n",
      " Minibatch accuracy: 85.9%\n",
      "  ***   Training set accuracy: 93.24% ***\n",
      "  *** Validation set accuracy: 90.39% ***\n",
      "Avg Minibatch loss for epoch 76: 0.363507\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 77: 0.360399\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 78: 0.360560\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 79: 0.359218\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 80: 0.358623\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 93.51% ***\n",
      "  *** Validation set accuracy: 90.50% ***\n",
      "Avg Minibatch loss for epoch 81: 0.357315\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 82: 0.355851\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 83: 0.354528\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 84: 0.353038\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 85: 0.352141\n",
      " Minibatch accuracy: 87.5%\n",
      "  ***   Training set accuracy: 93.48% ***\n",
      "  *** Validation set accuracy: 90.56% ***\n",
      "Avg Minibatch loss for epoch 86: 0.351183\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 87: 0.350396\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 88: 0.350584\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 89: 0.350923\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 90: 0.349551\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 93.81% ***\n",
      "  *** Validation set accuracy: 90.68% ***\n",
      "Avg Minibatch loss for epoch 91: 0.348064\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 92: 0.347415\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 93: 0.348108\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 94: 0.346669\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 95: 0.346931\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 93.80% ***\n",
      "  *** Validation set accuracy: 90.44% ***\n",
      "Avg Minibatch loss for epoch 96: 0.346984\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 97: 0.345258\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 98: 0.342352\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 99: 0.345032\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 100: 0.342641\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 93.95% ***\n",
      "  *** Validation set accuracy: 90.49% ***\n",
      "Avg Minibatch loss for epoch 101: 0.342791\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 102: 0.343393\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 103: 0.341880\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 104: 0.342852\n",
      " Minibatch accuracy: 92.2%\n",
      "Avg Minibatch loss for epoch 105: 0.340145\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 94.10% ***\n",
      "  *** Validation set accuracy: 90.51% ***\n",
      "Avg Minibatch loss for epoch 106: 0.340692\n",
      " Minibatch accuracy: 92.2%\n",
      "Avg Minibatch loss for epoch 107: 0.340687\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 108: 0.339523\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 109: 0.340418\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 110: 0.340265\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 94.17% ***\n",
      "  *** Validation set accuracy: 90.62% ***\n",
      "Avg Minibatch loss for epoch 111: 0.338492\n",
      " Minibatch accuracy: 93.8%\n",
      "Avg Minibatch loss for epoch 112: 0.339410\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 113: 0.337762\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 114: 0.339173\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 115: 0.338299\n",
      " Minibatch accuracy: 92.2%\n",
      "  ***   Training set accuracy: 94.22% ***\n",
      "  *** Validation set accuracy: 90.35% ***\n",
      "Avg Minibatch loss for epoch 116: 0.336884\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 117: 0.339417\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 118: 0.336313\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 119: 0.336031\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 120: 0.336587\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 94.27% ***\n",
      "  *** Validation set accuracy: 90.44% ***\n",
      "Avg Minibatch loss for epoch 121: 0.335005\n",
      " Minibatch accuracy: 93.8%\n",
      "Avg Minibatch loss for epoch 122: 0.335448\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 123: 0.337624\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 124: 0.334764\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 125: 0.335811\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 94.24% ***\n",
      "  *** Validation set accuracy: 90.51% ***\n",
      "Avg Minibatch loss for epoch 126: 0.333188\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 127: 0.335895\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 128: 0.334062\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 129: 0.333664\n",
      " Minibatch accuracy: 92.2%\n",
      "Avg Minibatch loss for epoch 130: 0.332258\n",
      " Minibatch accuracy: 92.2%\n",
      "  ***   Training set accuracy: 94.32% ***\n",
      "  *** Validation set accuracy: 90.55% ***\n",
      "Avg Minibatch loss for epoch 131: 0.335587\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 132: 0.334270\n",
      " Minibatch accuracy: 85.9%\n",
      "Avg Minibatch loss for epoch 133: 0.331471\n",
      " Minibatch accuracy: 93.8%\n",
      "Avg Minibatch loss for epoch 134: 0.333579\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 135: 0.332385\n",
      " Minibatch accuracy: 85.9%\n",
      "  ***   Training set accuracy: 94.33% ***\n",
      "  *** Validation set accuracy: 90.45% ***\n",
      "Avg Minibatch loss for epoch 136: 0.332112\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 137: 0.331817\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 138: 0.332279\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 139: 0.332158\n",
      " Minibatch accuracy: 98.4%\n",
      "Avg Minibatch loss for epoch 140: 0.330759\n",
      " Minibatch accuracy: 92.2%\n",
      "  ***   Training set accuracy: 94.44% ***\n",
      "  *** Validation set accuracy: 90.74% ***\n",
      "Avg Minibatch loss for epoch 141: 0.331455\n",
      " Minibatch accuracy: 82.8%\n",
      "Avg Minibatch loss for epoch 142: 0.330883\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 143: 0.330270\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 144: 0.331113\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 145: 0.330258\n",
      " Minibatch accuracy: 92.2%\n",
      "  ***   Training set accuracy: 94.61% ***\n",
      "  *** Validation set accuracy: 90.75% ***\n",
      "Avg Minibatch loss for epoch 146: 0.330579\n",
      " Minibatch accuracy: 95.3%\n",
      "Avg Minibatch loss for epoch 147: 0.330020\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 148: 0.329619\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 149: 0.329897\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 150: 0.329486\n",
      " Minibatch accuracy: 89.1%\n",
      "  ***   Training set accuracy: 94.64% ***\n",
      "  *** Validation set accuracy: 90.79% ***\n",
      "Avg Minibatch loss for epoch 151: 0.330664\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 152: 0.328960\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 153: 0.328331\n",
      " Minibatch accuracy: 96.9%\n",
      "Avg Minibatch loss for epoch 154: 0.328843\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 155: 0.329243\n",
      " Minibatch accuracy: 93.8%\n",
      "  ***   Training set accuracy: 94.67% ***\n",
      "  *** Validation set accuracy: 90.67% ***\n",
      "Avg Minibatch loss for epoch 156: 0.328348\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 157: 0.326456\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 158: 0.329650\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 159: 0.328461\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 160: 0.326723\n",
      " Minibatch accuracy: 90.6%\n",
      "  ***   Training set accuracy: 94.55% ***\n",
      "  *** Validation set accuracy: 90.75% ***\n",
      "Avg Minibatch loss for epoch 161: 0.327213\n",
      " Minibatch accuracy: 93.8%\n",
      "Avg Minibatch loss for epoch 162: 0.329150\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 163: 0.327665\n",
      " Minibatch accuracy: 92.2%\n",
      "Avg Minibatch loss for epoch 164: 0.326958\n",
      " Minibatch accuracy: 93.8%\n",
      "Avg Minibatch loss for epoch 165: 0.327221\n",
      " Minibatch accuracy: 93.8%\n",
      "  ***   Training set accuracy: 94.68% ***\n",
      "  *** Validation set accuracy: 90.60% ***\n",
      "Avg Minibatch loss for epoch 166: 0.327887\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 167: 0.327556\n",
      " Minibatch accuracy: 90.6%\n",
      "Avg Minibatch loss for epoch 168: 0.327257\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 169: 0.326600\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 170: 0.327190\n",
      " Minibatch accuracy: 85.9%\n",
      "  ***   Training set accuracy: 94.81% ***\n",
      "  *** Validation set accuracy: 90.65% ***\n",
      "Avg Minibatch loss for epoch 171: 0.327746\n",
      " Minibatch accuracy: 89.1%\n",
      "Avg Minibatch loss for epoch 172: 0.326940\n",
      " Minibatch accuracy: 92.2%\n",
      "Avg Minibatch loss for epoch 173: 0.327061\n",
      " Minibatch accuracy: 87.5%\n",
      "Avg Minibatch loss for epoch 174: 0.327317\n",
      " Minibatch accuracy: 93.8%\n",
      "\n",
      "Final Training set accuracy: 94.82%\n",
      "Final Validation set accuracy: 90.81%\n",
      "Test set accuracy: 96.17%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "h0 = 256\n",
    "h1 = 256\n",
    "h2 = 256\n",
    "lambda_ = 5e-5\n",
    "lr = .0005\n",
    "keep_prob = .675\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_tr_dataset = tf.constant(train_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    w0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    b0 = tf.Variable(tf.zeros([h0]))\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    b1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([h1, h2]))\n",
    "    b2 = tf.Variable(tf.zeros([h2]))\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2, num_labels]))\n",
    "    b3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0), keep_prob)\n",
    "    s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, w1) + b1), keep_prob)\n",
    "    s2 = tf.nn.relu(tf.matmul(s1, w2) + b2)\n",
    "    logits = tf.matmul(s2, w3) + b3\n",
    "\n",
    "    reg = tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)\n",
    "    # reg = tf.reduce_sum(tf.square(w0)) + tf.reduce_sum(tf.square(w1)) + tf.reduce_sum(tf.square(w1))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "\n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, w0) + b0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, w1) + b1)\n",
    "    v2 = tf.nn.relu(tf.matmul(v1, w2) + b2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v2, w3) + b3)\n",
    "\n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, w0) + b0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, w1) + b1)\n",
    "    t2 = tf.nn.relu(tf.matmul(t1, w2) + b2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t2, w3) + b3)\n",
    "    \n",
    "    r0 = tf.nn.relu(tf.matmul(tf_tr_dataset, w0) + b0)\n",
    "    r1 = tf.nn.relu(tf.matmul(r0, w1) + b1)\n",
    "    r2 = tf.nn.relu(tf.matmul(r1, w2) + b2)\n",
    "    tr_prediction = tf.nn.softmax(tf.matmul(r2, w3) + b3)\n",
    "\n",
    "batches = np.ceil(float(train_labels.shape[0]) / batch_size)\n",
    "num_epochs = 175\n",
    "num_steps = int(np.ceil(float(train_labels.shape[0]) / batch_size))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for epoch in range(num_epochs):\n",
    "        l_mean = 0\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            # offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            l_mean += l\n",
    "\n",
    "        print(\"Avg Minibatch loss for epoch %d: %f\" % (epoch, l_mean / num_steps))\n",
    "        print(\" Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "        if (epoch % 5 == 0):\n",
    "            print(\"  ***   Training set accuracy: %.2f%% ***\" % accuracy(tr_prediction.eval(), train_labels))\n",
    "            print(\"  *** Validation set accuracy: %.2f%% ***\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"\\nFinal Training set accuracy: %.2f%%\" % accuracy(tr_prediction.eval(), train_labels))\n",
    "    print(\"Final Validation set accuracy: %.2f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test set accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_w0 = w0\n",
    "best_w1 = w1\n",
    "best_w2 = w2\n",
    "best_w3 = w3\n",
    "\n",
    "best_b0 = b0\n",
    "best_b1 = b1\n",
    "best_b2 = b2\n",
    "best_b3 = b3\n",
    "\n",
    "best_lr = lr\n",
    "best_h0 = h0\n",
    "best_h1 = h1\n",
    "best_h2 = h2\n",
    "best_lambda = lambda_\n",
    "best_keep = keep_prob\n",
    "\n",
    "best_epochs = 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Avg Minibatch loss for epoch 0: 3335.316641\n",
      "  ***   Training set accuracy: 77.73% ***\n",
      "  *** Validation set accuracy: 77.30% ***\n",
      "Avg Minibatch loss for epoch 1: 1003.327266\n",
      "Avg Minibatch loss for epoch 2: 566.657956\n",
      "Avg Minibatch loss for epoch 3: 353.749486\n",
      "Avg Minibatch loss for epoch 4: 230.371917\n",
      "Avg Minibatch loss for epoch 5: 158.369888\n",
      "  ***   Training set accuracy: 61.99% ***\n",
      "  *** Validation set accuracy: 61.15% ***\n",
      "Avg Minibatch loss for epoch 6: 121.026956\n",
      "Avg Minibatch loss for epoch 7: 101.663283\n",
      "Avg Minibatch loss for epoch 8: 90.571421\n",
      "Avg Minibatch loss for epoch 9: 83.337551\n",
      "Avg Minibatch loss for epoch 10: 78.015060\n",
      "  ***   Training set accuracy: 40.87% ***\n",
      "  *** Validation set accuracy: 40.73% ***\n",
      "Avg Minibatch loss for epoch 11: 73.526497\n",
      "Avg Minibatch loss for epoch 12: 69.317634\n",
      "Avg Minibatch loss for epoch 13: 65.063659\n",
      "Avg Minibatch loss for epoch 14: 60.674348\n",
      "Avg Minibatch loss for epoch 15: 56.178468\n",
      "  ***   Training set accuracy: 41.42% ***\n",
      "  *** Validation set accuracy: 40.88% ***\n",
      "Avg Minibatch loss for epoch 16: 51.418605\n",
      "Avg Minibatch loss for epoch 17: 46.327121\n",
      "Avg Minibatch loss for epoch 18: 41.005695\n",
      "Avg Minibatch loss for epoch 19: 35.416706\n",
      "Avg Minibatch loss for epoch 20: 29.657767\n",
      "  ***   Training set accuracy: 52.16% ***\n",
      "  *** Validation set accuracy: 51.31% ***\n",
      "Avg Minibatch loss for epoch 21: 23.833088\n",
      "Avg Minibatch loss for epoch 22: 18.271378\n",
      "Avg Minibatch loss for epoch 23: 13.366212\n",
      "Avg Minibatch loss for epoch 24: 9.327995\n",
      "Avg Minibatch loss for epoch 25: 6.276578\n",
      "  ***   Training set accuracy: 79.91% ***\n",
      "  *** Validation set accuracy: 79.07% ***\n",
      "Avg Minibatch loss for epoch 26: 4.076369\n",
      "Avg Minibatch loss for epoch 27: 2.595941\n",
      "Avg Minibatch loss for epoch 28: 1.686576\n",
      "Avg Minibatch loss for epoch 29: 1.161778\n",
      "Avg Minibatch loss for epoch 30: 0.872628\n",
      "  ***   Training set accuracy: 88.26% ***\n",
      "  *** Validation set accuracy: 87.41% ***\n",
      "Avg Minibatch loss for epoch 31: 0.711715\n",
      "Avg Minibatch loss for epoch 32: 0.622988\n",
      "Avg Minibatch loss for epoch 33: 0.571819\n",
      "Avg Minibatch loss for epoch 34: 0.542217\n",
      "Avg Minibatch loss for epoch 35: 0.525065\n",
      "  ***   Training set accuracy: 89.54% ***\n",
      "  *** Validation set accuracy: 88.26% ***\n",
      "Avg Minibatch loss for epoch 36: 0.511456\n",
      "Avg Minibatch loss for epoch 37: 0.503252\n",
      "Avg Minibatch loss for epoch 38: 0.496790\n",
      "Avg Minibatch loss for epoch 39: 0.491931\n",
      "Avg Minibatch loss for epoch 40: 0.488401\n",
      "  ***   Training set accuracy: 89.98% ***\n",
      "  *** Validation set accuracy: 88.86% ***\n",
      "Avg Minibatch loss for epoch 41: 0.482859\n",
      "Avg Minibatch loss for epoch 42: 0.481436\n",
      "Avg Minibatch loss for epoch 43: 0.479303\n",
      "Avg Minibatch loss for epoch 44: 0.478736\n",
      "Avg Minibatch loss for epoch 45: 0.475865\n",
      "  ***   Training set accuracy: 90.39% ***\n",
      "  *** Validation set accuracy: 89.03% ***\n",
      "Avg Minibatch loss for epoch 46: 0.475194\n",
      "Avg Minibatch loss for epoch 47: 0.472783\n",
      "Avg Minibatch loss for epoch 48: 0.472040\n",
      "Avg Minibatch loss for epoch 49: 0.471395\n",
      "Avg Minibatch loss for epoch 50: 0.470588\n",
      "  ***   Training set accuracy: 90.44% ***\n",
      "  *** Validation set accuracy: 88.77% ***\n",
      "Avg Minibatch loss for epoch 51: 0.468681\n",
      "Avg Minibatch loss for epoch 52: 0.468062\n",
      "Avg Minibatch loss for epoch 53: 0.467179\n",
      "Avg Minibatch loss for epoch 54: 0.466550\n",
      "Avg Minibatch loss for epoch 55: 0.466632\n",
      "  ***   Training set accuracy: 90.67% ***\n",
      "  *** Validation set accuracy: 89.26% ***\n",
      "Avg Minibatch loss for epoch 56: 0.466922\n",
      "Avg Minibatch loss for epoch 57: 0.464671\n",
      "Avg Minibatch loss for epoch 58: 0.463688\n",
      "Avg Minibatch loss for epoch 59: 0.464422\n",
      "Avg Minibatch loss for epoch 60: 0.463092\n",
      "  ***   Training set accuracy: 90.77% ***\n",
      "  *** Validation set accuracy: 89.30% ***\n",
      "Avg Minibatch loss for epoch 61: 0.463245\n",
      "Avg Minibatch loss for epoch 62: 0.461646\n",
      "Avg Minibatch loss for epoch 63: 0.460405\n",
      "Avg Minibatch loss for epoch 64: 0.462015\n",
      "Avg Minibatch loss for epoch 65: 0.459509\n",
      "  ***   Training set accuracy: 90.78% ***\n",
      "  *** Validation set accuracy: 88.98% ***\n",
      "Avg Minibatch loss for epoch 66: 0.459245\n",
      "Avg Minibatch loss for epoch 67: 0.459610\n",
      "Avg Minibatch loss for epoch 68: 0.458493\n",
      "Avg Minibatch loss for epoch 69: 0.458339\n",
      "Avg Minibatch loss for epoch 70: 0.458559\n",
      "  ***   Training set accuracy: 90.99% ***\n",
      "  *** Validation set accuracy: 89.45% ***\n",
      "Avg Minibatch loss for epoch 71: 0.457325\n",
      "Avg Minibatch loss for epoch 72: 0.457588\n",
      "Avg Minibatch loss for epoch 73: 0.456129\n",
      "Avg Minibatch loss for epoch 74: 0.456540\n",
      "Avg Minibatch loss for epoch 75: 0.454633\n",
      "  ***   Training set accuracy: 90.99% ***\n",
      "  *** Validation set accuracy: 89.58% ***\n",
      "Avg Minibatch loss for epoch 76: 0.456049\n",
      "Avg Minibatch loss for epoch 77: 0.454554\n",
      "Avg Minibatch loss for epoch 78: 0.454099\n",
      "Avg Minibatch loss for epoch 79: 0.453304\n",
      "Avg Minibatch loss for epoch 80: 0.454484\n",
      "  ***   Training set accuracy: 91.03% ***\n",
      "  *** Validation set accuracy: 89.26% ***\n",
      "Avg Minibatch loss for epoch 81: 0.453155\n",
      "Avg Minibatch loss for epoch 82: 0.452799\n",
      "Avg Minibatch loss for epoch 83: 0.453212\n",
      "Avg Minibatch loss for epoch 84: 0.453352\n",
      "Avg Minibatch loss for epoch 85: 0.453502\n",
      "  ***   Training set accuracy: 91.26% ***\n",
      "  *** Validation set accuracy: 89.58% ***\n",
      "Avg Minibatch loss for epoch 86: 0.452715\n",
      "Avg Minibatch loss for epoch 87: 0.452767\n",
      "Avg Minibatch loss for epoch 88: 0.451738\n",
      "Avg Minibatch loss for epoch 89: 0.452267\n",
      "Avg Minibatch loss for epoch 90: 0.450357\n",
      "  ***   Training set accuracy: 91.19% ***\n",
      "  *** Validation set accuracy: 89.46% ***\n",
      "Avg Minibatch loss for epoch 91: 0.451539\n",
      "Avg Minibatch loss for epoch 92: 0.449782\n",
      "Avg Minibatch loss for epoch 93: 0.451992\n",
      "Avg Minibatch loss for epoch 94: 0.450019\n",
      "Avg Minibatch loss for epoch 95: 0.450225\n",
      "  ***   Training set accuracy: 91.15% ***\n",
      "  *** Validation set accuracy: 89.45% ***\n",
      "Avg Minibatch loss for epoch 96: 0.450083\n",
      "Avg Minibatch loss for epoch 97: 0.450227\n",
      "Avg Minibatch loss for epoch 98: 0.449985\n",
      "Avg Minibatch loss for epoch 99: 0.449306\n",
      "Avg Minibatch loss for epoch 100: 0.448906\n",
      "  ***   Training set accuracy: 91.33% ***\n",
      "  *** Validation set accuracy: 89.54% ***\n",
      "Avg Minibatch loss for epoch 101: 0.448933\n",
      "Avg Minibatch loss for epoch 102: 0.448403\n",
      "Avg Minibatch loss for epoch 103: 0.448229\n",
      "Avg Minibatch loss for epoch 104: 0.448278\n",
      "Avg Minibatch loss for epoch 105: 0.449740\n",
      "  ***   Training set accuracy: 91.07% ***\n",
      "  *** Validation set accuracy: 89.42% ***\n",
      "Avg Minibatch loss for epoch 106: 0.448376\n",
      "Avg Minibatch loss for epoch 107: 0.447602\n",
      "Avg Minibatch loss for epoch 108: 0.448511\n",
      "Avg Minibatch loss for epoch 109: 0.447851\n",
      "Avg Minibatch loss for epoch 110: 0.449122\n",
      "  ***   Training set accuracy: 91.33% ***\n",
      "  *** Validation set accuracy: 89.59% ***\n",
      "Avg Minibatch loss for epoch 111: 0.448345\n",
      "Avg Minibatch loss for epoch 112: 0.447119\n",
      "Avg Minibatch loss for epoch 113: 0.447904\n",
      "Avg Minibatch loss for epoch 114: 0.446499\n",
      "Avg Minibatch loss for epoch 115: 0.446608\n",
      "  ***   Training set accuracy: 91.31% ***\n",
      "  *** Validation set accuracy: 89.55% ***\n",
      "Avg Minibatch loss for epoch 116: 0.447437\n",
      "Avg Minibatch loss for epoch 117: 0.447556\n",
      "Avg Minibatch loss for epoch 118: 0.447556\n",
      "Avg Minibatch loss for epoch 119: 0.446658\n",
      "Avg Minibatch loss for epoch 120: 0.447314\n",
      "  ***   Training set accuracy: 91.40% ***\n",
      "  *** Validation set accuracy: 89.62% ***\n",
      "Avg Minibatch loss for epoch 121: 0.446923\n",
      "Avg Minibatch loss for epoch 122: 0.446206\n",
      "Avg Minibatch loss for epoch 123: 0.445643\n",
      "Avg Minibatch loss for epoch 124: 0.447673\n",
      "Avg Minibatch loss for epoch 125: 0.445473\n",
      "  ***   Training set accuracy: 91.29% ***\n",
      "  *** Validation set accuracy: 89.61% ***\n",
      "Avg Minibatch loss for epoch 126: 0.446496\n",
      "Avg Minibatch loss for epoch 127: 0.445887\n",
      "Avg Minibatch loss for epoch 128: 0.446920\n",
      "Avg Minibatch loss for epoch 129: 0.446259\n",
      "Avg Minibatch loss for epoch 130: 0.445849\n",
      "  ***   Training set accuracy: 91.52% ***\n",
      "  *** Validation set accuracy: 89.88% ***\n",
      "Avg Minibatch loss for epoch 131: 0.445562\n",
      "Avg Minibatch loss for epoch 132: 0.444648\n",
      "Avg Minibatch loss for epoch 133: 0.444223\n",
      "Avg Minibatch loss for epoch 134: 0.444585\n",
      "Avg Minibatch loss for epoch 135: 0.443949\n",
      "  ***   Training set accuracy: 91.59% ***\n",
      "  *** Validation set accuracy: 89.82% ***\n",
      "Avg Minibatch loss for epoch 136: 0.445657\n",
      "Avg Minibatch loss for epoch 137: 0.444565\n",
      "Avg Minibatch loss for epoch 138: 0.444461\n",
      "Avg Minibatch loss for epoch 139: 0.444775\n",
      "Avg Minibatch loss for epoch 140: 0.444309\n",
      "  ***   Training set accuracy: 91.34% ***\n",
      "  *** Validation set accuracy: 89.46% ***\n",
      "Avg Minibatch loss for epoch 141: 0.444806\n",
      "Avg Minibatch loss for epoch 142: 0.445478\n",
      "Avg Minibatch loss for epoch 143: 0.444695\n",
      "Avg Minibatch loss for epoch 144: 0.443672\n",
      "Avg Minibatch loss for epoch 145: 0.445029\n",
      "  ***   Training set accuracy: 91.42% ***\n",
      "  *** Validation set accuracy: 89.57% ***\n",
      "Avg Minibatch loss for epoch 146: 0.444853\n",
      "Avg Minibatch loss for epoch 147: 0.444003\n",
      "Avg Minibatch loss for epoch 148: 0.444622\n",
      "Avg Minibatch loss for epoch 149: 0.445175\n",
      "Avg Minibatch loss for epoch 150: 0.445184\n",
      "  ***   Training set accuracy: 91.48% ***\n",
      "  *** Validation set accuracy: 89.75% ***\n",
      "Avg Minibatch loss for epoch 151: 0.444802\n",
      "Avg Minibatch loss for epoch 152: 0.444461\n",
      "Avg Minibatch loss for epoch 153: 0.444871\n",
      "Avg Minibatch loss for epoch 154: 0.442945\n",
      "Avg Minibatch loss for epoch 155: 0.442757\n",
      "  ***   Training set accuracy: 91.38% ***\n",
      "  *** Validation set accuracy: 89.36% ***\n",
      "Avg Minibatch loss for epoch 156: 0.443297\n",
      "Avg Minibatch loss for epoch 157: 0.443932\n",
      "Avg Minibatch loss for epoch 158: 0.443882\n",
      "Avg Minibatch loss for epoch 159: 0.442872\n",
      "Avg Minibatch loss for epoch 160: 0.444420\n",
      "  ***   Training set accuracy: 91.55% ***\n",
      "  *** Validation set accuracy: 89.83% ***\n",
      "Avg Minibatch loss for epoch 161: 0.444691\n",
      "Avg Minibatch loss for epoch 162: 0.443554\n",
      "Avg Minibatch loss for epoch 163: 0.444549\n",
      "Avg Minibatch loss for epoch 164: 0.443739\n",
      "Avg Minibatch loss for epoch 165: 0.443901\n",
      "  ***   Training set accuracy: 91.35% ***\n",
      "  *** Validation set accuracy: 89.43% ***\n",
      "Avg Minibatch loss for epoch 166: 0.444532\n",
      "Avg Minibatch loss for epoch 167: 0.443007\n",
      "Avg Minibatch loss for epoch 168: 0.443539\n",
      "Avg Minibatch loss for epoch 169: 0.443362\n",
      "Avg Minibatch loss for epoch 170: 0.444039\n",
      "  ***   Training set accuracy: 91.53% ***\n",
      "  *** Validation set accuracy: 89.84% ***\n",
      "Avg Minibatch loss for epoch 171: 0.442443\n",
      "Avg Minibatch loss for epoch 172: 0.443751\n",
      "Avg Minibatch loss for epoch 173: 0.442589\n",
      "Avg Minibatch loss for epoch 174: 0.442538\n",
      "\n",
      "Final Training set accuracy: 91.56%\n",
      "Final Validation set accuracy: 89.41%\n",
      "Test set accuracy: 95.44%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "h0 = 256\n",
    "h1 = 256\n",
    "h2 = 256\n",
    "lambda_ = 6e-4\n",
    "lr = .000375\n",
    "keep_prob = .675\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_tr_dataset = tf.constant(train_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    w0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "    b0 = tf.Variable(tf.zeros([h0]))\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "    b1 = tf.Variable(tf.zeros([h1]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([h1, h2]))\n",
    "    b2 = tf.Variable(tf.zeros([h2]))\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2, num_labels]))\n",
    "    b3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0), keep_prob)\n",
    "    s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, w1) + b1), keep_prob)\n",
    "    s2 = tf.nn.relu(tf.matmul(s1, w2) + b2)\n",
    "    logits = tf.matmul(s2, w3) + b3\n",
    "\n",
    "    reg = tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)\n",
    "    # reg = tf.reduce_sum(tf.square(w0)) + tf.reduce_sum(tf.square(w1)) + tf.reduce_sum(tf.square(w1))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "\n",
    "    # Optimizer.\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, w0) + b0)\n",
    "    v1 = tf.nn.relu(tf.matmul(v0, w1) + b1)\n",
    "    v2 = tf.nn.relu(tf.matmul(v1, w2) + b2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(v2, w3) + b3)\n",
    "\n",
    "    t0 = tf.nn.relu(tf.matmul(tf_test_dataset, w0) + b0)\n",
    "    t1 = tf.nn.relu(tf.matmul(t0, w1) + b1)\n",
    "    t2 = tf.nn.relu(tf.matmul(t1, w2) + b2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(t2, w3) + b3)\n",
    "    \n",
    "    r0 = tf.nn.relu(tf.matmul(tf_tr_dataset, w0) + b0)\n",
    "    r1 = tf.nn.relu(tf.matmul(r0, w1) + b1)\n",
    "    r2 = tf.nn.relu(tf.matmul(r1, w2) + b2)\n",
    "    tr_prediction = tf.nn.softmax(tf.matmul(r2, w3) + b3)\n",
    "\n",
    "batches = np.ceil(float(train_labels.shape[0]) / batch_size)\n",
    "num_epochs = 175\n",
    "num_steps = int(np.ceil(float(train_labels.shape[0]) / batch_size))\n",
    "curves = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for epoch in range(num_epochs):\n",
    "        l_mean = 0\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            # offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            l_mean += l\n",
    "\n",
    "        print(\"Avg Minibatch loss for epoch %d: %f\" % (epoch, l_mean / num_steps))\n",
    "        # print(\" Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "        if (epoch % 5 == 0):\n",
    "            tra = accuracy(tr_prediction.eval(), train_labels)\n",
    "            va = accuracy(valid_prediction.eval(), valid_labels)\n",
    "            print(\"  ***   Training set accuracy: %.2f%% ***\" % tra)\n",
    "            print(\"  *** Validation set accuracy: %.2f%% ***\" % va)\n",
    "            curves.append({'epoch': epoch, 'train': 1 - tra, 'val': 1- va})\n",
    "    print(\"\\nFinal Training set accuracy: %.2f%%\" % accuracy(tr_prediction.eval(), train_labels))\n",
    "    print(\"Final Validation set accuracy: %.2f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test set accuracy: %.2f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run size 500 initialized\n",
      "   Avg Minibatch loss for epoch 0: 1768.132651\n",
      "     ***   Training set accuracy: 98.80% ***\n",
      "     *** Validation set accuracy: 76.55% ***\n",
      "   Avg Minibatch loss for epoch 1: 120.038027\n",
      "   Avg Minibatch loss for epoch 2: 42.229033\n",
      "   Avg Minibatch loss for epoch 3: 22.663578\n",
      "   Avg Minibatch loss for epoch 4: 15.800269\n",
      "   Avg Minibatch loss for epoch 5: 13.092072\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.52% ***\n",
      "   Avg Minibatch loss for epoch 6: 11.596330\n",
      "   Avg Minibatch loss for epoch 7: 10.199064\n",
      "   Avg Minibatch loss for epoch 8: 9.460913\n",
      "   Avg Minibatch loss for epoch 9: 9.408908\n",
      "   Avg Minibatch loss for epoch 10: 8.506672\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.34% ***\n",
      "   Avg Minibatch loss for epoch 11: 8.565779\n",
      "   Avg Minibatch loss for epoch 12: 8.128609\n",
      "   Avg Minibatch loss for epoch 13: 7.745308\n",
      "   Avg Minibatch loss for epoch 14: 7.899625\n",
      "   Avg Minibatch loss for epoch 15: 7.265811\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.57% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.492246\n",
      "   Avg Minibatch loss for epoch 17: 7.366100\n",
      "   Avg Minibatch loss for epoch 18: 7.516488\n",
      "   Avg Minibatch loss for epoch 19: 7.594780\n",
      "   Avg Minibatch loss for epoch 20: 7.173061\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.83% ***\n",
      "   Avg Minibatch loss for epoch 21: 7.271558\n",
      "   Avg Minibatch loss for epoch 22: 6.928668\n",
      "   Avg Minibatch loss for epoch 23: 7.092393\n",
      "   Avg Minibatch loss for epoch 24: 7.188210\n",
      "   Avg Minibatch loss for epoch 25: 6.936208\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.48% ***\n",
      "   Avg Minibatch loss for epoch 26: 6.911793\n",
      "   Avg Minibatch loss for epoch 27: 6.955850\n",
      "   Avg Minibatch loss for epoch 28: 6.748598\n",
      "   Avg Minibatch loss for epoch 29: 6.997435\n",
      "   Avg Minibatch loss for epoch 30: 6.753492\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.11% ***\n",
      "   Avg Minibatch loss for epoch 31: 6.685755\n",
      "   Avg Minibatch loss for epoch 32: 6.609989\n",
      "   Avg Minibatch loss for epoch 33: 6.472320\n",
      "   Avg Minibatch loss for epoch 34: 6.667494\n",
      "   Avg Minibatch loss for epoch 35: 6.469194\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.05% ***\n",
      "   Avg Minibatch loss for epoch 36: 6.613188\n",
      "   Avg Minibatch loss for epoch 37: 6.484246\n",
      "   Avg Minibatch loss for epoch 38: 6.586871\n",
      "   Avg Minibatch loss for epoch 39: 6.364759\n",
      "   Avg Minibatch loss for epoch 40: 6.196458\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.39% ***\n",
      "   Avg Minibatch loss for epoch 41: 6.269349\n",
      "   Avg Minibatch loss for epoch 42: 6.280037\n",
      "   Avg Minibatch loss for epoch 43: 6.318215\n",
      "   Avg Minibatch loss for epoch 44: 6.366150\n",
      "   Avg Minibatch loss for epoch 45: 6.117736\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.28% ***\n",
      "   Avg Minibatch loss for epoch 46: 6.461267\n",
      "   Avg Minibatch loss for epoch 47: 6.114796\n",
      "   Avg Minibatch loss for epoch 48: 5.988716\n",
      "   Avg Minibatch loss for epoch 49: 6.037896\n",
      "   Avg Minibatch loss for epoch 50: 6.260854\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.91% ***\n",
      "   Avg Minibatch loss for epoch 51: 6.017052\n",
      "   Avg Minibatch loss for epoch 52: 6.154955\n",
      "   Avg Minibatch loss for epoch 53: 5.838372\n",
      "   Avg Minibatch loss for epoch 54: 5.761570\n",
      "   Avg Minibatch loss for epoch 55: 5.898442\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.18% ***\n",
      "   Avg Minibatch loss for epoch 56: 5.897942\n",
      "   Avg Minibatch loss for epoch 57: 5.835085\n",
      "   Avg Minibatch loss for epoch 58: 5.822935\n",
      "   Avg Minibatch loss for epoch 59: 5.680565\n",
      "   Avg Minibatch loss for epoch 60: 5.765772\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.94% ***\n",
      "   Avg Minibatch loss for epoch 61: 5.682446\n",
      "   Avg Minibatch loss for epoch 62: 5.647947\n",
      "   Avg Minibatch loss for epoch 63: 5.696675\n",
      "   Avg Minibatch loss for epoch 64: 5.561399\n",
      "   Avg Minibatch loss for epoch 65: 5.625652\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.73% ***\n",
      "   Avg Minibatch loss for epoch 66: 5.491252\n",
      "   Avg Minibatch loss for epoch 67: 5.440652\n",
      "   Avg Minibatch loss for epoch 68: 5.469423\n",
      "   Avg Minibatch loss for epoch 69: 5.351914\n",
      "   Avg Minibatch loss for epoch 70: 5.462788\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.85% ***\n",
      "   Avg Minibatch loss for epoch 71: 5.371696\n",
      "   Avg Minibatch loss for epoch 72: 5.331476\n",
      "   Avg Minibatch loss for epoch 73: 5.284566\n",
      "   Avg Minibatch loss for epoch 74: 5.314640\n",
      "   Avg Minibatch loss for epoch 75: 5.131868\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.14% ***\n",
      "   Avg Minibatch loss for epoch 76: 5.219286\n",
      "   Avg Minibatch loss for epoch 77: 5.192916\n",
      "   Avg Minibatch loss for epoch 78: 5.083445\n",
      "   Avg Minibatch loss for epoch 79: 5.023929\n",
      "   Avg Minibatch loss for epoch 80: 5.051742\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.99% ***\n",
      "   Avg Minibatch loss for epoch 81: 4.896136\n",
      "   Avg Minibatch loss for epoch 82: 4.951680\n",
      "   Avg Minibatch loss for epoch 83: 4.984529\n",
      "   Avg Minibatch loss for epoch 84: 4.969670\n",
      "   Avg Minibatch loss for epoch 85: 4.849470\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.61% ***\n",
      "   Avg Minibatch loss for epoch 86: 4.754378\n",
      "   Avg Minibatch loss for epoch 87: 4.729192\n",
      "   Avg Minibatch loss for epoch 88: 4.781646\n",
      "   Avg Minibatch loss for epoch 89: 4.758514\n",
      "   Avg Minibatch loss for epoch 90: 4.728398\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.98% ***\n",
      "   Avg Minibatch loss for epoch 91: 4.589500\n",
      "   Avg Minibatch loss for epoch 92: 4.572371\n",
      "   Avg Minibatch loss for epoch 93: 4.625251\n",
      "   Avg Minibatch loss for epoch 94: 4.654816\n",
      "   Avg Minibatch loss for epoch 95: 4.439090\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.09% ***\n",
      "   Avg Minibatch loss for epoch 96: 4.425502\n",
      "   Avg Minibatch loss for epoch 97: 4.414183\n",
      "   Avg Minibatch loss for epoch 98: 4.411554\n",
      "   Avg Minibatch loss for epoch 99: 4.442703\n",
      "   Avg Minibatch loss for epoch 100: 4.353044\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.94% ***\n",
      "   Avg Minibatch loss for epoch 101: 4.379194\n",
      "   Avg Minibatch loss for epoch 102: 4.287789\n",
      "   Avg Minibatch loss for epoch 103: 4.175301\n",
      "   Avg Minibatch loss for epoch 104: 4.343320\n",
      "   Avg Minibatch loss for epoch 105: 4.133224\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.39% ***\n",
      "   Avg Minibatch loss for epoch 106: 4.251013\n",
      "   Avg Minibatch loss for epoch 107: 4.101439\n",
      "   Avg Minibatch loss for epoch 108: 4.094518\n",
      "   Avg Minibatch loss for epoch 109: 4.126446\n",
      "   Avg Minibatch loss for epoch 110: 4.013824\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.04% ***\n",
      "   Avg Minibatch loss for epoch 111: 4.085682\n",
      "   Avg Minibatch loss for epoch 112: 3.925113\n",
      "   Avg Minibatch loss for epoch 113: 3.906862\n",
      "   Avg Minibatch loss for epoch 114: 3.968044\n",
      "   Avg Minibatch loss for epoch 115: 3.918182\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.49% ***\n",
      "   Avg Minibatch loss for epoch 116: 3.792857\n",
      "   Avg Minibatch loss for epoch 117: 3.794991\n",
      "   Avg Minibatch loss for epoch 118: 3.699650\n",
      "   Avg Minibatch loss for epoch 119: 3.676080\n",
      "   Avg Minibatch loss for epoch 120: 3.652404\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 78.75% ***\n",
      "   Avg Minibatch loss for epoch 121: 3.636178\n",
      "   Avg Minibatch loss for epoch 122: 3.560811\n",
      "   Avg Minibatch loss for epoch 123: 3.545585\n",
      "   Avg Minibatch loss for epoch 124: 3.464709\n",
      "\n",
      "   Final Training set accuracy: 100.00%\n",
      "   Final Validation set accuracy: 78.69%\n",
      "   Test set accuracy: 85.89%\n",
      "\n",
      "\n",
      "Run size 1000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2219.984774\n",
      "     ***   Training set accuracy: 98.00% ***\n",
      "     *** Validation set accuracy: 76.81% ***\n",
      "   Avg Minibatch loss for epoch 1: 254.827741\n",
      "   Avg Minibatch loss for epoch 2: 94.083380\n",
      "   Avg Minibatch loss for epoch 3: 48.949312\n",
      "   Avg Minibatch loss for epoch 4: 30.473058\n",
      "   Avg Minibatch loss for epoch 5: 21.563212\n",
      "     ***   Training set accuracy: 99.80% ***\n",
      "     *** Validation set accuracy: 78.91% ***\n",
      "   Avg Minibatch loss for epoch 6: 17.661717\n",
      "   Avg Minibatch loss for epoch 7: 15.118251\n",
      "   Avg Minibatch loss for epoch 8: 13.361472\n",
      "   Avg Minibatch loss for epoch 9: 12.294721\n",
      "   Avg Minibatch loss for epoch 10: 11.233443\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.30% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.802508\n",
      "   Avg Minibatch loss for epoch 12: 9.856308\n",
      "   Avg Minibatch loss for epoch 13: 9.793864\n",
      "   Avg Minibatch loss for epoch 14: 8.988046\n",
      "   Avg Minibatch loss for epoch 15: 8.991672\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.40% ***\n",
      "   Avg Minibatch loss for epoch 16: 8.482441\n",
      "   Avg Minibatch loss for epoch 17: 8.579930\n",
      "   Avg Minibatch loss for epoch 18: 8.303836\n",
      "   Avg Minibatch loss for epoch 19: 8.006803\n",
      "   Avg Minibatch loss for epoch 20: 7.790097\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.32% ***\n",
      "   Avg Minibatch loss for epoch 21: 7.833441\n",
      "   Avg Minibatch loss for epoch 22: 7.661485\n",
      "   Avg Minibatch loss for epoch 23: 7.808002\n",
      "   Avg Minibatch loss for epoch 24: 7.641304\n",
      "   Avg Minibatch loss for epoch 25: 7.542510\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.34% ***\n",
      "   Avg Minibatch loss for epoch 26: 7.411915\n",
      "   Avg Minibatch loss for epoch 27: 7.320654\n",
      "   Avg Minibatch loss for epoch 28: 7.084950\n",
      "   Avg Minibatch loss for epoch 29: 7.206342\n",
      "   Avg Minibatch loss for epoch 30: 7.132765\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.37% ***\n",
      "   Avg Minibatch loss for epoch 31: 7.060843\n",
      "   Avg Minibatch loss for epoch 32: 7.131281\n",
      "   Avg Minibatch loss for epoch 33: 7.095334\n",
      "   Avg Minibatch loss for epoch 34: 6.942629\n",
      "   Avg Minibatch loss for epoch 35: 7.125701\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.11% ***\n",
      "   Avg Minibatch loss for epoch 36: 6.884188\n",
      "   Avg Minibatch loss for epoch 37: 6.842394\n",
      "   Avg Minibatch loss for epoch 38: 6.806183\n",
      "   Avg Minibatch loss for epoch 39: 6.826426\n",
      "   Avg Minibatch loss for epoch 40: 6.812073\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.33% ***\n",
      "   Avg Minibatch loss for epoch 41: 6.539865\n",
      "   Avg Minibatch loss for epoch 42: 6.601362\n",
      "   Avg Minibatch loss for epoch 43: 6.561857\n",
      "   Avg Minibatch loss for epoch 44: 6.499388\n",
      "   Avg Minibatch loss for epoch 45: 6.366990\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.66% ***\n",
      "   Avg Minibatch loss for epoch 46: 6.626726\n",
      "   Avg Minibatch loss for epoch 47: 6.574248\n",
      "   Avg Minibatch loss for epoch 48: 6.363472\n",
      "   Avg Minibatch loss for epoch 49: 6.220778\n",
      "   Avg Minibatch loss for epoch 50: 6.329170\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.15% ***\n",
      "   Avg Minibatch loss for epoch 51: 6.371581\n",
      "   Avg Minibatch loss for epoch 52: 6.297892\n",
      "   Avg Minibatch loss for epoch 53: 6.275524\n",
      "   Avg Minibatch loss for epoch 54: 6.131652\n",
      "   Avg Minibatch loss for epoch 55: 6.145513\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.53% ***\n",
      "   Avg Minibatch loss for epoch 56: 6.201500\n",
      "   Avg Minibatch loss for epoch 57: 5.928560\n",
      "   Avg Minibatch loss for epoch 58: 6.131132\n",
      "   Avg Minibatch loss for epoch 59: 6.100887\n",
      "   Avg Minibatch loss for epoch 60: 5.921547\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 78.95% ***\n",
      "   Avg Minibatch loss for epoch 61: 5.998781\n",
      "   Avg Minibatch loss for epoch 62: 5.871169\n",
      "   Avg Minibatch loss for epoch 63: 5.792092\n",
      "   Avg Minibatch loss for epoch 64: 5.925729\n",
      "   Avg Minibatch loss for epoch 65: 5.818814\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.35% ***\n",
      "   Avg Minibatch loss for epoch 66: 5.732865\n",
      "   Avg Minibatch loss for epoch 67: 5.781136\n",
      "   Avg Minibatch loss for epoch 68: 5.726098\n",
      "   Avg Minibatch loss for epoch 69: 5.686270\n",
      "   Avg Minibatch loss for epoch 70: 5.660720\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.60% ***\n",
      "   Avg Minibatch loss for epoch 71: 5.592939\n",
      "   Avg Minibatch loss for epoch 72: 5.449126\n",
      "   Avg Minibatch loss for epoch 73: 5.535784\n",
      "   Avg Minibatch loss for epoch 74: 5.483228\n",
      "   Avg Minibatch loss for epoch 75: 5.348620\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.30% ***\n",
      "   Avg Minibatch loss for epoch 76: 5.339653\n",
      "   Avg Minibatch loss for epoch 77: 5.484634\n",
      "   Avg Minibatch loss for epoch 78: 5.436901\n",
      "   Avg Minibatch loss for epoch 79: 5.308581\n",
      "   Avg Minibatch loss for epoch 80: 5.345630\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.32% ***\n",
      "   Avg Minibatch loss for epoch 81: 5.371437\n",
      "   Avg Minibatch loss for epoch 82: 5.183429\n",
      "   Avg Minibatch loss for epoch 83: 5.168484\n",
      "   Avg Minibatch loss for epoch 84: 5.166941\n",
      "   Avg Minibatch loss for epoch 85: 5.052102\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.15% ***\n",
      "   Avg Minibatch loss for epoch 86: 5.050794\n",
      "   Avg Minibatch loss for epoch 87: 5.103659\n",
      "   Avg Minibatch loss for epoch 88: 4.996942\n",
      "   Avg Minibatch loss for epoch 89: 5.050924\n",
      "   Avg Minibatch loss for epoch 90: 5.028105\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.40% ***\n",
      "   Avg Minibatch loss for epoch 91: 5.021406\n",
      "   Avg Minibatch loss for epoch 92: 4.983661\n",
      "   Avg Minibatch loss for epoch 93: 4.959529\n",
      "   Avg Minibatch loss for epoch 94: 4.944328\n",
      "   Avg Minibatch loss for epoch 95: 4.941479\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.39% ***\n",
      "   Avg Minibatch loss for epoch 96: 4.885033\n",
      "   Avg Minibatch loss for epoch 97: 4.780980\n",
      "   Avg Minibatch loss for epoch 98: 4.753037\n",
      "   Avg Minibatch loss for epoch 99: 4.790737\n",
      "   Avg Minibatch loss for epoch 100: 4.695059\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.41% ***\n",
      "   Avg Minibatch loss for epoch 101: 4.791418\n",
      "   Avg Minibatch loss for epoch 102: 4.675148\n",
      "   Avg Minibatch loss for epoch 103: 4.604076\n",
      "   Avg Minibatch loss for epoch 104: 4.623374\n",
      "   Avg Minibatch loss for epoch 105: 4.563276\n",
      "     ***   Training set accuracy: 100.00% ***\n",
      "     *** Validation set accuracy: 79.52% ***\n",
      "   Avg Minibatch loss for epoch 106: 4.553635\n",
      "   Avg Minibatch loss for epoch 107: 4.434892\n",
      "   Avg Minibatch loss for epoch 108: 4.513136\n",
      "   Avg Minibatch loss for epoch 109: 4.428558\n",
      "   Avg Minibatch loss for epoch 110: 4.371852\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.47% ***\n",
      "   Avg Minibatch loss for epoch 111: 4.435343\n",
      "   Avg Minibatch loss for epoch 112: 4.357053\n",
      "   Avg Minibatch loss for epoch 113: 4.342714\n",
      "   Avg Minibatch loss for epoch 114: 4.216276\n",
      "   Avg Minibatch loss for epoch 115: 4.317423\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.19% ***\n",
      "   Avg Minibatch loss for epoch 116: 4.281453\n",
      "   Avg Minibatch loss for epoch 117: 4.140443\n",
      "   Avg Minibatch loss for epoch 118: 4.200980\n",
      "   Avg Minibatch loss for epoch 119: 4.070763\n",
      "   Avg Minibatch loss for epoch 120: 4.174357\n",
      "     ***   Training set accuracy: 99.90% ***\n",
      "     *** Validation set accuracy: 79.41% ***\n",
      "   Avg Minibatch loss for epoch 121: 4.035975\n",
      "   Avg Minibatch loss for epoch 122: 4.050786\n",
      "   Avg Minibatch loss for epoch 123: 4.065171\n",
      "   Avg Minibatch loss for epoch 124: 4.038388\n",
      "\n",
      "   Final Training set accuracy: 99.90%\n",
      "   Final Validation set accuracy: 79.39%\n",
      "   Test set accuracy: 86.72%\n",
      "\n",
      "\n",
      "Run size 2500 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2462.441874\n",
      "     ***   Training set accuracy: 89.20% ***\n",
      "     *** Validation set accuracy: 76.77% ***\n",
      "   Avg Minibatch loss for epoch 1: 472.892228\n",
      "   Avg Minibatch loss for epoch 2: 205.291462\n",
      "   Avg Minibatch loss for epoch 3: 110.850400\n",
      "   Avg Minibatch loss for epoch 4: 69.246256\n",
      "   Avg Minibatch loss for epoch 5: 48.403162\n",
      "     ***   Training set accuracy: 99.32% ***\n",
      "     *** Validation set accuracy: 79.32% ***\n",
      "   Avg Minibatch loss for epoch 6: 35.796217\n",
      "   Avg Minibatch loss for epoch 7: 27.939399\n",
      "   Avg Minibatch loss for epoch 8: 22.437211\n",
      "   Avg Minibatch loss for epoch 9: 18.837969\n",
      "   Avg Minibatch loss for epoch 10: 16.258221\n",
      "     ***   Training set accuracy: 99.56% ***\n",
      "     *** Validation set accuracy: 79.43% ***\n",
      "   Avg Minibatch loss for epoch 11: 14.577230\n",
      "   Avg Minibatch loss for epoch 12: 13.102103\n",
      "   Avg Minibatch loss for epoch 13: 11.822751\n",
      "   Avg Minibatch loss for epoch 14: 11.151148\n",
      "   Avg Minibatch loss for epoch 15: 10.758046\n",
      "     ***   Training set accuracy: 99.48% ***\n",
      "     *** Validation set accuracy: 79.80% ***\n",
      "   Avg Minibatch loss for epoch 16: 10.100445\n",
      "   Avg Minibatch loss for epoch 17: 9.595493\n",
      "   Avg Minibatch loss for epoch 18: 9.466288\n",
      "   Avg Minibatch loss for epoch 19: 9.002125\n",
      "   Avg Minibatch loss for epoch 20: 8.749993\n",
      "     ***   Training set accuracy: 99.28% ***\n",
      "     *** Validation set accuracy: 79.77% ***\n",
      "   Avg Minibatch loss for epoch 21: 8.448956\n",
      "   Avg Minibatch loss for epoch 22: 8.155852\n",
      "   Avg Minibatch loss for epoch 23: 8.073411\n",
      "   Avg Minibatch loss for epoch 24: 7.870604\n",
      "   Avg Minibatch loss for epoch 25: 7.811597\n",
      "     ***   Training set accuracy: 99.32% ***\n",
      "     *** Validation set accuracy: 80.07% ***\n",
      "   Avg Minibatch loss for epoch 26: 7.662958\n",
      "   Avg Minibatch loss for epoch 27: 7.469415\n",
      "   Avg Minibatch loss for epoch 28: 7.277174\n",
      "   Avg Minibatch loss for epoch 29: 7.233893\n",
      "   Avg Minibatch loss for epoch 30: 7.213164\n",
      "     ***   Training set accuracy: 99.44% ***\n",
      "     *** Validation set accuracy: 80.03% ***\n",
      "   Avg Minibatch loss for epoch 31: 6.973493\n",
      "   Avg Minibatch loss for epoch 32: 6.965904\n",
      "   Avg Minibatch loss for epoch 33: 6.896373\n",
      "   Avg Minibatch loss for epoch 34: 6.751202\n",
      "   Avg Minibatch loss for epoch 35: 6.767578\n",
      "     ***   Training set accuracy: 99.36% ***\n",
      "     *** Validation set accuracy: 80.01% ***\n",
      "   Avg Minibatch loss for epoch 36: 6.783271\n",
      "   Avg Minibatch loss for epoch 37: 6.506734\n",
      "   Avg Minibatch loss for epoch 38: 6.481012\n",
      "   Avg Minibatch loss for epoch 39: 6.390112\n",
      "   Avg Minibatch loss for epoch 40: 6.361842\n",
      "     ***   Training set accuracy: 99.16% ***\n",
      "     *** Validation set accuracy: 79.86% ***\n",
      "   Avg Minibatch loss for epoch 41: 6.382729\n",
      "   Avg Minibatch loss for epoch 42: 6.204950\n",
      "   Avg Minibatch loss for epoch 43: 6.128796\n",
      "   Avg Minibatch loss for epoch 44: 6.044906\n",
      "   Avg Minibatch loss for epoch 45: 6.038318\n",
      "     ***   Training set accuracy: 99.52% ***\n",
      "     *** Validation set accuracy: 80.10% ***\n",
      "   Avg Minibatch loss for epoch 46: 5.946298\n",
      "   Avg Minibatch loss for epoch 47: 5.917507\n",
      "   Avg Minibatch loss for epoch 48: 5.891987\n",
      "   Avg Minibatch loss for epoch 49: 5.817753\n",
      "   Avg Minibatch loss for epoch 50: 5.755213\n",
      "     ***   Training set accuracy: 99.48% ***\n",
      "     *** Validation set accuracy: 80.04% ***\n",
      "   Avg Minibatch loss for epoch 51: 5.668816\n",
      "   Avg Minibatch loss for epoch 52: 5.595014\n",
      "   Avg Minibatch loss for epoch 53: 5.623133\n",
      "   Avg Minibatch loss for epoch 54: 5.514394\n",
      "   Avg Minibatch loss for epoch 55: 5.467570\n",
      "     ***   Training set accuracy: 99.36% ***\n",
      "     *** Validation set accuracy: 79.93% ***\n",
      "   Avg Minibatch loss for epoch 56: 5.414060\n",
      "   Avg Minibatch loss for epoch 57: 5.392990\n",
      "   Avg Minibatch loss for epoch 58: 5.297990\n",
      "   Avg Minibatch loss for epoch 59: 5.230328\n",
      "   Avg Minibatch loss for epoch 60: 5.199382\n",
      "     ***   Training set accuracy: 99.48% ***\n",
      "     *** Validation set accuracy: 79.88% ***\n",
      "   Avg Minibatch loss for epoch 61: 5.092463\n",
      "   Avg Minibatch loss for epoch 62: 5.045934\n",
      "   Avg Minibatch loss for epoch 63: 5.062753\n",
      "   Avg Minibatch loss for epoch 64: 4.948457\n",
      "   Avg Minibatch loss for epoch 65: 4.915664\n",
      "     ***   Training set accuracy: 99.44% ***\n",
      "     *** Validation set accuracy: 80.40% ***\n",
      "   Avg Minibatch loss for epoch 66: 4.870197\n",
      "   Avg Minibatch loss for epoch 67: 4.805403\n",
      "   Avg Minibatch loss for epoch 68: 4.699144\n",
      "   Avg Minibatch loss for epoch 69: 4.697637\n",
      "   Avg Minibatch loss for epoch 70: 4.639559\n",
      "     ***   Training set accuracy: 99.36% ***\n",
      "     *** Validation set accuracy: 80.26% ***\n",
      "   Avg Minibatch loss for epoch 71: 4.610703\n",
      "   Avg Minibatch loss for epoch 72: 4.544552\n",
      "   Avg Minibatch loss for epoch 73: 4.501319\n",
      "   Avg Minibatch loss for epoch 74: 4.433758\n",
      "   Avg Minibatch loss for epoch 75: 4.357321\n",
      "     ***   Training set accuracy: 99.56% ***\n",
      "     *** Validation set accuracy: 80.39% ***\n",
      "   Avg Minibatch loss for epoch 76: 4.289560\n",
      "   Avg Minibatch loss for epoch 77: 4.259368\n",
      "   Avg Minibatch loss for epoch 78: 4.211832\n",
      "   Avg Minibatch loss for epoch 79: 4.162521\n",
      "   Avg Minibatch loss for epoch 80: 4.085484\n",
      "     ***   Training set accuracy: 99.52% ***\n",
      "     *** Validation set accuracy: 80.14% ***\n",
      "   Avg Minibatch loss for epoch 81: 4.024666\n",
      "   Avg Minibatch loss for epoch 82: 3.989933\n",
      "   Avg Minibatch loss for epoch 83: 3.899034\n",
      "   Avg Minibatch loss for epoch 84: 3.873074\n",
      "   Avg Minibatch loss for epoch 85: 3.833697\n",
      "     ***   Training set accuracy: 99.60% ***\n",
      "     *** Validation set accuracy: 80.41% ***\n",
      "   Avg Minibatch loss for epoch 86: 3.743998\n",
      "   Avg Minibatch loss for epoch 87: 3.702391\n",
      "   Avg Minibatch loss for epoch 88: 3.640930\n",
      "   Avg Minibatch loss for epoch 89: 3.613108\n",
      "   Avg Minibatch loss for epoch 90: 3.556669\n",
      "     ***   Training set accuracy: 99.60% ***\n",
      "     *** Validation set accuracy: 80.45% ***\n",
      "   Avg Minibatch loss for epoch 91: 3.498287\n",
      "   Avg Minibatch loss for epoch 92: 3.433196\n",
      "   Avg Minibatch loss for epoch 93: 3.368827\n",
      "   Avg Minibatch loss for epoch 94: 3.357918\n",
      "   Avg Minibatch loss for epoch 95: 3.264828\n",
      "     ***   Training set accuracy: 99.60% ***\n",
      "     *** Validation set accuracy: 80.27% ***\n",
      "   Avg Minibatch loss for epoch 96: 3.238073\n",
      "   Avg Minibatch loss for epoch 97: 3.181851\n",
      "   Avg Minibatch loss for epoch 98: 3.124289\n",
      "   Avg Minibatch loss for epoch 99: 3.050420\n",
      "   Avg Minibatch loss for epoch 100: 3.002770\n",
      "     ***   Training set accuracy: 99.68% ***\n",
      "     *** Validation set accuracy: 80.35% ***\n",
      "   Avg Minibatch loss for epoch 101: 2.939052\n",
      "   Avg Minibatch loss for epoch 102: 2.903197\n",
      "   Avg Minibatch loss for epoch 103: 2.830708\n",
      "   Avg Minibatch loss for epoch 104: 2.789763\n",
      "   Avg Minibatch loss for epoch 105: 2.715386\n",
      "     ***   Training set accuracy: 99.64% ***\n",
      "     *** Validation set accuracy: 80.47% ***\n",
      "   Avg Minibatch loss for epoch 106: 2.659279\n",
      "   Avg Minibatch loss for epoch 107: 2.615984\n",
      "   Avg Minibatch loss for epoch 108: 2.557647\n",
      "   Avg Minibatch loss for epoch 109: 2.508842\n",
      "   Avg Minibatch loss for epoch 110: 2.442329\n",
      "     ***   Training set accuracy: 99.64% ***\n",
      "     *** Validation set accuracy: 80.37% ***\n",
      "   Avg Minibatch loss for epoch 111: 2.401026\n",
      "   Avg Minibatch loss for epoch 112: 2.336261\n",
      "   Avg Minibatch loss for epoch 113: 2.272327\n",
      "   Avg Minibatch loss for epoch 114: 2.252127\n",
      "   Avg Minibatch loss for epoch 115: 2.178387\n",
      "     ***   Training set accuracy: 99.68% ***\n",
      "     *** Validation set accuracy: 80.61% ***\n",
      "   Avg Minibatch loss for epoch 116: 2.135594\n",
      "   Avg Minibatch loss for epoch 117: 2.067851\n",
      "   Avg Minibatch loss for epoch 118: 2.021465\n",
      "   Avg Minibatch loss for epoch 119: 1.968138\n",
      "   Avg Minibatch loss for epoch 120: 1.907880\n",
      "     ***   Training set accuracy: 99.76% ***\n",
      "     *** Validation set accuracy: 80.32% ***\n",
      "   Avg Minibatch loss for epoch 121: 1.837333\n",
      "   Avg Minibatch loss for epoch 122: 1.787380\n",
      "   Avg Minibatch loss for epoch 123: 1.731247\n",
      "   Avg Minibatch loss for epoch 124: 1.682665\n",
      "\n",
      "   Final Training set accuracy: 99.72%\n",
      "   Final Validation set accuracy: 80.29%\n",
      "   Test set accuracy: 87.75%\n",
      "\n",
      "\n",
      "Run size 5000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2762.262419\n",
      "     ***   Training set accuracy: 83.90% ***\n",
      "     *** Validation set accuracy: 77.75% ***\n",
      "   Avg Minibatch loss for epoch 1: 615.180396\n",
      "   Avg Minibatch loss for epoch 2: 296.159235\n",
      "   Avg Minibatch loss for epoch 3: 161.024745\n",
      "   Avg Minibatch loss for epoch 4: 95.221498\n",
      "   Avg Minibatch loss for epoch 5: 60.974213\n",
      "     ***   Training set accuracy: 95.62% ***\n",
      "     *** Validation set accuracy: 78.00% ***\n",
      "   Avg Minibatch loss for epoch 6: 41.399266\n",
      "   Avg Minibatch loss for epoch 7: 29.839032\n",
      "   Avg Minibatch loss for epoch 8: 22.716619\n",
      "   Avg Minibatch loss for epoch 9: 18.034174\n",
      "   Avg Minibatch loss for epoch 10: 14.875014\n",
      "     ***   Training set accuracy: 91.28% ***\n",
      "     *** Validation set accuracy: 75.03% ***\n",
      "   Avg Minibatch loss for epoch 11: 12.988063\n",
      "   Avg Minibatch loss for epoch 12: 11.421579\n",
      "   Avg Minibatch loss for epoch 13: 10.484120\n",
      "   Avg Minibatch loss for epoch 14: 9.708568\n",
      "   Avg Minibatch loss for epoch 15: 9.159849\n",
      "     ***   Training set accuracy: 88.92% ***\n",
      "     *** Validation set accuracy: 73.82% ***\n",
      "   Avg Minibatch loss for epoch 16: 8.734605\n",
      "   Avg Minibatch loss for epoch 17: 8.341672\n",
      "   Avg Minibatch loss for epoch 18: 7.984892\n",
      "   Avg Minibatch loss for epoch 19: 7.782115\n",
      "   Avg Minibatch loss for epoch 20: 7.530922\n",
      "     ***   Training set accuracy: 88.10% ***\n",
      "     *** Validation set accuracy: 73.18% ***\n",
      "   Avg Minibatch loss for epoch 21: 7.276055\n",
      "   Avg Minibatch loss for epoch 22: 7.207010\n",
      "   Avg Minibatch loss for epoch 23: 7.030037\n",
      "   Avg Minibatch loss for epoch 24: 6.888053\n",
      "   Avg Minibatch loss for epoch 25: 6.738600\n",
      "     ***   Training set accuracy: 88.84% ***\n",
      "     *** Validation set accuracy: 73.87% ***\n",
      "   Avg Minibatch loss for epoch 26: 6.616220\n",
      "   Avg Minibatch loss for epoch 27: 6.499582\n",
      "   Avg Minibatch loss for epoch 28: 6.348963\n",
      "   Avg Minibatch loss for epoch 29: 6.213697\n",
      "   Avg Minibatch loss for epoch 30: 6.136754\n",
      "     ***   Training set accuracy: 89.52% ***\n",
      "     *** Validation set accuracy: 74.45% ***\n",
      "   Avg Minibatch loss for epoch 31: 5.993460\n",
      "   Avg Minibatch loss for epoch 32: 5.903609\n",
      "   Avg Minibatch loss for epoch 33: 5.791784\n",
      "   Avg Minibatch loss for epoch 34: 5.685068\n",
      "   Avg Minibatch loss for epoch 35: 5.554603\n",
      "     ***   Training set accuracy: 90.24% ***\n",
      "     *** Validation set accuracy: 74.84% ***\n",
      "   Avg Minibatch loss for epoch 36: 5.483672\n",
      "   Avg Minibatch loss for epoch 37: 5.335296\n",
      "   Avg Minibatch loss for epoch 38: 5.271258\n",
      "   Avg Minibatch loss for epoch 39: 5.161242\n",
      "   Avg Minibatch loss for epoch 40: 5.022986\n",
      "     ***   Training set accuracy: 91.06% ***\n",
      "     *** Validation set accuracy: 75.17% ***\n",
      "   Avg Minibatch loss for epoch 41: 4.949304\n",
      "   Avg Minibatch loss for epoch 42: 4.871332\n",
      "   Avg Minibatch loss for epoch 43: 4.731591\n",
      "   Avg Minibatch loss for epoch 44: 4.657108\n",
      "   Avg Minibatch loss for epoch 45: 4.533882\n",
      "     ***   Training set accuracy: 91.76% ***\n",
      "     *** Validation set accuracy: 75.61% ***\n",
      "   Avg Minibatch loss for epoch 46: 4.446828\n",
      "   Avg Minibatch loss for epoch 47: 4.353583\n",
      "   Avg Minibatch loss for epoch 48: 4.254841\n",
      "   Avg Minibatch loss for epoch 49: 4.162245\n",
      "   Avg Minibatch loss for epoch 50: 4.049796\n",
      "     ***   Training set accuracy: 92.32% ***\n",
      "     *** Validation set accuracy: 76.39% ***\n",
      "   Avg Minibatch loss for epoch 51: 3.944266\n",
      "   Avg Minibatch loss for epoch 52: 3.853602\n",
      "   Avg Minibatch loss for epoch 53: 3.755095\n",
      "   Avg Minibatch loss for epoch 54: 3.648833\n",
      "   Avg Minibatch loss for epoch 55: 3.552301\n",
      "     ***   Training set accuracy: 93.16% ***\n",
      "     *** Validation set accuracy: 76.87% ***\n",
      "   Avg Minibatch loss for epoch 56: 3.459051\n",
      "   Avg Minibatch loss for epoch 57: 3.359426\n",
      "   Avg Minibatch loss for epoch 58: 3.269233\n",
      "   Avg Minibatch loss for epoch 59: 3.156832\n",
      "   Avg Minibatch loss for epoch 60: 3.049992\n",
      "     ***   Training set accuracy: 94.02% ***\n",
      "     *** Validation set accuracy: 77.54% ***\n",
      "   Avg Minibatch loss for epoch 61: 2.952806\n",
      "   Avg Minibatch loss for epoch 62: 2.860675\n",
      "   Avg Minibatch loss for epoch 63: 2.748571\n",
      "   Avg Minibatch loss for epoch 64: 2.651009\n",
      "   Avg Minibatch loss for epoch 65: 2.555695\n",
      "     ***   Training set accuracy: 94.66% ***\n",
      "     *** Validation set accuracy: 78.03% ***\n",
      "   Avg Minibatch loss for epoch 66: 2.458631\n",
      "   Avg Minibatch loss for epoch 67: 2.364223\n",
      "   Avg Minibatch loss for epoch 68: 2.260580\n",
      "   Avg Minibatch loss for epoch 69: 2.174438\n",
      "   Avg Minibatch loss for epoch 70: 2.077253\n",
      "     ***   Training set accuracy: 95.40% ***\n",
      "     *** Validation set accuracy: 78.64% ***\n",
      "   Avg Minibatch loss for epoch 71: 1.979571\n",
      "   Avg Minibatch loss for epoch 72: 1.886326\n",
      "   Avg Minibatch loss for epoch 73: 1.783434\n",
      "   Avg Minibatch loss for epoch 74: 1.689256\n",
      "   Avg Minibatch loss for epoch 75: 1.595882\n",
      "     ***   Training set accuracy: 96.48% ***\n",
      "     *** Validation set accuracy: 79.41% ***\n",
      "   Avg Minibatch loss for epoch 76: 1.505090\n",
      "   Avg Minibatch loss for epoch 77: 1.424247\n",
      "   Avg Minibatch loss for epoch 78: 1.328471\n",
      "   Avg Minibatch loss for epoch 79: 1.243166\n",
      "   Avg Minibatch loss for epoch 80: 1.156734\n",
      "     ***   Training set accuracy: 97.56% ***\n",
      "     *** Validation set accuracy: 80.06% ***\n",
      "   Avg Minibatch loss for epoch 81: 1.082443\n",
      "   Avg Minibatch loss for epoch 82: 1.005520\n",
      "   Avg Minibatch loss for epoch 83: 0.926824\n",
      "   Avg Minibatch loss for epoch 84: 0.855170\n",
      "   Avg Minibatch loss for epoch 85: 0.789115\n",
      "     ***   Training set accuracy: 98.76% ***\n",
      "     *** Validation set accuracy: 80.86% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.724206\n",
      "   Avg Minibatch loss for epoch 87: 0.662109\n",
      "   Avg Minibatch loss for epoch 88: 0.606285\n",
      "   Avg Minibatch loss for epoch 89: 0.553324\n",
      "   Avg Minibatch loss for epoch 90: 0.504253\n",
      "     ***   Training set accuracy: 99.50% ***\n",
      "     *** Validation set accuracy: 81.54% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.459295\n",
      "   Avg Minibatch loss for epoch 92: 0.418972\n",
      "   Avg Minibatch loss for epoch 93: 0.383602\n",
      "   Avg Minibatch loss for epoch 94: 0.350653\n",
      "   Avg Minibatch loss for epoch 95: 0.321091\n",
      "     ***   Training set accuracy: 99.66% ***\n",
      "     *** Validation set accuracy: 82.05% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.292754\n",
      "   Avg Minibatch loss for epoch 97: 0.270030\n",
      "   Avg Minibatch loss for epoch 98: 0.248047\n",
      "   Avg Minibatch loss for epoch 99: 0.228729\n",
      "   Avg Minibatch loss for epoch 100: 0.209840\n",
      "     ***   Training set accuracy: 99.82% ***\n",
      "     *** Validation set accuracy: 82.47% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.194587\n",
      "   Avg Minibatch loss for epoch 102: 0.179275\n",
      "   Avg Minibatch loss for epoch 103: 0.168270\n",
      "   Avg Minibatch loss for epoch 104: 0.155594\n",
      "   Avg Minibatch loss for epoch 105: 0.146119\n",
      "     ***   Training set accuracy: 99.76% ***\n",
      "     *** Validation set accuracy: 82.44% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.136841\n",
      "   Avg Minibatch loss for epoch 107: 0.128724\n",
      "   Avg Minibatch loss for epoch 108: 0.120301\n",
      "   Avg Minibatch loss for epoch 109: 0.114059\n",
      "   Avg Minibatch loss for epoch 110: 0.107785\n",
      "     ***   Training set accuracy: 99.86% ***\n",
      "     *** Validation set accuracy: 82.59% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.102288\n",
      "   Avg Minibatch loss for epoch 112: 0.097933\n",
      "   Avg Minibatch loss for epoch 113: 0.093204\n",
      "   Avg Minibatch loss for epoch 114: 0.088656\n",
      "   Avg Minibatch loss for epoch 115: 0.085253\n",
      "     ***   Training set accuracy: 99.86% ***\n",
      "     *** Validation set accuracy: 82.82% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.082272\n",
      "   Avg Minibatch loss for epoch 117: 0.078693\n",
      "   Avg Minibatch loss for epoch 118: 0.076582\n",
      "   Avg Minibatch loss for epoch 119: 0.074209\n",
      "   Avg Minibatch loss for epoch 120: 0.072979\n",
      "     ***   Training set accuracy: 99.80% ***\n",
      "     *** Validation set accuracy: 82.52% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.069615\n",
      "   Avg Minibatch loss for epoch 122: 0.068975\n",
      "   Avg Minibatch loss for epoch 123: 0.067287\n",
      "   Avg Minibatch loss for epoch 124: 0.065563\n",
      "\n",
      "   Final Training set accuracy: 99.82%\n",
      "   Final Validation set accuracy: 82.94%\n",
      "   Test set accuracy: 90.45%\n",
      "\n",
      "\n",
      "Run size 10000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2775.033203\n",
      "     ***   Training set accuracy: 81.17% ***\n",
      "     *** Validation set accuracy: 77.52% ***\n",
      "   Avg Minibatch loss for epoch 1: 678.771906\n",
      "   Avg Minibatch loss for epoch 2: 325.404886\n",
      "   Avg Minibatch loss for epoch 3: 173.325745\n",
      "   Avg Minibatch loss for epoch 4: 93.692384\n",
      "   Avg Minibatch loss for epoch 5: 52.365121\n",
      "     ***   Training set accuracy: 77.58% ***\n",
      "     *** Validation set accuracy: 67.93% ***\n",
      "   Avg Minibatch loss for epoch 6: 31.882648\n",
      "   Avg Minibatch loss for epoch 7: 21.579774\n",
      "   Avg Minibatch loss for epoch 8: 16.087006\n",
      "   Avg Minibatch loss for epoch 9: 13.119637\n",
      "   Avg Minibatch loss for epoch 10: 11.216549\n",
      "     ***   Training set accuracy: 66.37% ***\n",
      "     *** Validation set accuracy: 59.60% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.269235\n",
      "   Avg Minibatch loss for epoch 12: 9.364193\n",
      "   Avg Minibatch loss for epoch 13: 8.814358\n",
      "   Avg Minibatch loss for epoch 14: 8.341772\n",
      "   Avg Minibatch loss for epoch 15: 8.082100\n",
      "     ***   Training set accuracy: 65.58% ***\n",
      "     *** Validation set accuracy: 59.19% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.830937\n",
      "   Avg Minibatch loss for epoch 17: 7.582637\n",
      "   Avg Minibatch loss for epoch 18: 7.342352\n",
      "   Avg Minibatch loss for epoch 19: 7.179962\n",
      "   Avg Minibatch loss for epoch 20: 6.985318\n",
      "     ***   Training set accuracy: 66.57% ***\n",
      "     *** Validation set accuracy: 59.67% ***\n",
      "   Avg Minibatch loss for epoch 21: 6.772563\n",
      "   Avg Minibatch loss for epoch 22: 6.634404\n",
      "   Avg Minibatch loss for epoch 23: 6.435650\n",
      "   Avg Minibatch loss for epoch 24: 6.285830\n",
      "   Avg Minibatch loss for epoch 25: 6.138700\n",
      "     ***   Training set accuracy: 70.17% ***\n",
      "     *** Validation set accuracy: 62.58% ***\n",
      "   Avg Minibatch loss for epoch 26: 5.942710\n",
      "   Avg Minibatch loss for epoch 27: 5.829819\n",
      "   Avg Minibatch loss for epoch 28: 5.670680\n",
      "   Avg Minibatch loss for epoch 29: 5.510921\n",
      "   Avg Minibatch loss for epoch 30: 5.358129\n",
      "     ***   Training set accuracy: 73.17% ***\n",
      "     *** Validation set accuracy: 65.32% ***\n",
      "   Avg Minibatch loss for epoch 31: 5.224844\n",
      "   Avg Minibatch loss for epoch 32: 5.084747\n",
      "   Avg Minibatch loss for epoch 33: 4.929815\n",
      "   Avg Minibatch loss for epoch 34: 4.794110\n",
      "   Avg Minibatch loss for epoch 35: 4.644400\n",
      "     ***   Training set accuracy: 75.99% ***\n",
      "     *** Validation set accuracy: 68.38% ***\n",
      "   Avg Minibatch loss for epoch 36: 4.490482\n",
      "   Avg Minibatch loss for epoch 37: 4.350822\n",
      "   Avg Minibatch loss for epoch 38: 4.202455\n",
      "   Avg Minibatch loss for epoch 39: 4.060886\n",
      "   Avg Minibatch loss for epoch 40: 3.951316\n",
      "     ***   Training set accuracy: 78.11% ***\n",
      "     *** Validation set accuracy: 70.15% ***\n",
      "   Avg Minibatch loss for epoch 41: 3.807074\n",
      "   Avg Minibatch loss for epoch 42: 3.664079\n",
      "   Avg Minibatch loss for epoch 43: 3.531213\n",
      "   Avg Minibatch loss for epoch 44: 3.390605\n",
      "   Avg Minibatch loss for epoch 45: 3.261748\n",
      "     ***   Training set accuracy: 81.42% ***\n",
      "     *** Validation set accuracy: 72.78% ***\n",
      "   Avg Minibatch loss for epoch 46: 3.126927\n",
      "   Avg Minibatch loss for epoch 47: 2.996357\n",
      "   Avg Minibatch loss for epoch 48: 2.872794\n",
      "   Avg Minibatch loss for epoch 49: 2.752084\n",
      "   Avg Minibatch loss for epoch 50: 2.630526\n",
      "     ***   Training set accuracy: 84.03% ***\n",
      "     *** Validation set accuracy: 74.66% ***\n",
      "   Avg Minibatch loss for epoch 51: 2.502947\n",
      "   Avg Minibatch loss for epoch 52: 2.395793\n",
      "   Avg Minibatch loss for epoch 53: 2.275036\n",
      "   Avg Minibatch loss for epoch 54: 2.153136\n",
      "   Avg Minibatch loss for epoch 55: 2.044928\n",
      "     ***   Training set accuracy: 87.64% ***\n",
      "     *** Validation set accuracy: 76.69% ***\n",
      "   Avg Minibatch loss for epoch 56: 1.934486\n",
      "   Avg Minibatch loss for epoch 57: 1.826051\n",
      "   Avg Minibatch loss for epoch 58: 1.722336\n",
      "   Avg Minibatch loss for epoch 59: 1.621636\n",
      "   Avg Minibatch loss for epoch 60: 1.525411\n",
      "     ***   Training set accuracy: 91.48% ***\n",
      "     *** Validation set accuracy: 78.94% ***\n",
      "   Avg Minibatch loss for epoch 61: 1.421925\n",
      "   Avg Minibatch loss for epoch 62: 1.336741\n",
      "   Avg Minibatch loss for epoch 63: 1.247206\n",
      "   Avg Minibatch loss for epoch 64: 1.165397\n",
      "   Avg Minibatch loss for epoch 65: 1.084672\n",
      "     ***   Training set accuracy: 94.66% ***\n",
      "     *** Validation set accuracy: 80.65% ***\n",
      "   Avg Minibatch loss for epoch 66: 1.011387\n",
      "   Avg Minibatch loss for epoch 67: 0.939649\n",
      "   Avg Minibatch loss for epoch 68: 0.870044\n",
      "   Avg Minibatch loss for epoch 69: 0.809350\n",
      "   Avg Minibatch loss for epoch 70: 0.748668\n",
      "     ***   Training set accuracy: 97.47% ***\n",
      "     *** Validation set accuracy: 81.49% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.697842\n",
      "   Avg Minibatch loss for epoch 72: 0.647903\n",
      "   Avg Minibatch loss for epoch 73: 0.605710\n",
      "   Avg Minibatch loss for epoch 74: 0.560020\n",
      "   Avg Minibatch loss for epoch 75: 0.521263\n",
      "     ***   Training set accuracy: 98.69% ***\n",
      "     *** Validation set accuracy: 82.27% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.484401\n",
      "   Avg Minibatch loss for epoch 77: 0.450472\n",
      "   Avg Minibatch loss for epoch 78: 0.420440\n",
      "   Avg Minibatch loss for epoch 79: 0.393535\n",
      "   Avg Minibatch loss for epoch 80: 0.367784\n",
      "     ***   Training set accuracy: 99.28% ***\n",
      "     *** Validation set accuracy: 82.64% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.344979\n",
      "   Avg Minibatch loss for epoch 82: 0.323010\n",
      "   Avg Minibatch loss for epoch 83: 0.303306\n",
      "   Avg Minibatch loss for epoch 84: 0.284043\n",
      "   Avg Minibatch loss for epoch 85: 0.268726\n",
      "     ***   Training set accuracy: 99.56% ***\n",
      "     *** Validation set accuracy: 83.61% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.252649\n",
      "   Avg Minibatch loss for epoch 87: 0.239073\n",
      "   Avg Minibatch loss for epoch 88: 0.228071\n",
      "   Avg Minibatch loss for epoch 89: 0.215950\n",
      "   Avg Minibatch loss for epoch 90: 0.204334\n",
      "     ***   Training set accuracy: 99.69% ***\n",
      "     *** Validation set accuracy: 83.81% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.196286\n",
      "   Avg Minibatch loss for epoch 92: 0.187056\n",
      "   Avg Minibatch loss for epoch 93: 0.179282\n",
      "   Avg Minibatch loss for epoch 94: 0.171124\n",
      "   Avg Minibatch loss for epoch 95: 0.165199\n",
      "     ***   Training set accuracy: 99.73% ***\n",
      "     *** Validation set accuracy: 83.95% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.159008\n",
      "   Avg Minibatch loss for epoch 97: 0.152673\n",
      "   Avg Minibatch loss for epoch 98: 0.146658\n",
      "   Avg Minibatch loss for epoch 99: 0.143052\n",
      "   Avg Minibatch loss for epoch 100: 0.138212\n",
      "     ***   Training set accuracy: 99.77% ***\n",
      "     *** Validation set accuracy: 84.41% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.133823\n",
      "   Avg Minibatch loss for epoch 102: 0.129509\n",
      "   Avg Minibatch loss for epoch 103: 0.125787\n",
      "   Avg Minibatch loss for epoch 104: 0.123819\n",
      "   Avg Minibatch loss for epoch 105: 0.119256\n",
      "     ***   Training set accuracy: 99.77% ***\n",
      "     *** Validation set accuracy: 84.38% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.116806\n",
      "   Avg Minibatch loss for epoch 107: 0.115160\n",
      "   Avg Minibatch loss for epoch 108: 0.111274\n",
      "   Avg Minibatch loss for epoch 109: 0.109936\n",
      "   Avg Minibatch loss for epoch 110: 0.107773\n",
      "     ***   Training set accuracy: 99.78% ***\n",
      "     *** Validation set accuracy: 84.41% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.106154\n",
      "   Avg Minibatch loss for epoch 112: 0.103187\n",
      "   Avg Minibatch loss for epoch 113: 0.101857\n",
      "   Avg Minibatch loss for epoch 114: 0.100766\n",
      "   Avg Minibatch loss for epoch 115: 0.099936\n",
      "     ***   Training set accuracy: 99.77% ***\n",
      "     *** Validation set accuracy: 84.55% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.097495\n",
      "   Avg Minibatch loss for epoch 117: 0.096838\n",
      "   Avg Minibatch loss for epoch 118: 0.095925\n",
      "   Avg Minibatch loss for epoch 119: 0.094154\n",
      "   Avg Minibatch loss for epoch 120: 0.093211\n",
      "     ***   Training set accuracy: 99.76% ***\n",
      "     *** Validation set accuracy: 84.19% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.092128\n",
      "   Avg Minibatch loss for epoch 122: 0.091131\n",
      "   Avg Minibatch loss for epoch 123: 0.090063\n",
      "   Avg Minibatch loss for epoch 124: 0.089542\n",
      "\n",
      "   Final Training set accuracy: 99.79%\n",
      "   Final Validation set accuracy: 84.69%\n",
      "   Test set accuracy: 91.05%\n",
      "\n",
      "\n",
      "Run size 25000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2734.452093\n",
      "     ***   Training set accuracy: 79.41% ***\n",
      "     *** Validation set accuracy: 77.79% ***\n",
      "   Avg Minibatch loss for epoch 1: 691.353624\n",
      "   Avg Minibatch loss for epoch 2: 339.563749\n",
      "   Avg Minibatch loss for epoch 3: 171.786018\n",
      "   Avg Minibatch loss for epoch 4: 87.191958\n",
      "   Avg Minibatch loss for epoch 5: 48.125046\n",
      "     ***   Training set accuracy: 63.70% ***\n",
      "     *** Validation set accuracy: 60.40% ***\n",
      "   Avg Minibatch loss for epoch 6: 29.489642\n",
      "   Avg Minibatch loss for epoch 7: 20.539766\n",
      "   Avg Minibatch loss for epoch 8: 15.750277\n",
      "   Avg Minibatch loss for epoch 9: 13.067641\n",
      "   Avg Minibatch loss for epoch 10: 11.318857\n",
      "     ***   Training set accuracy: 51.63% ***\n",
      "     *** Validation set accuracy: 47.87% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.235600\n",
      "   Avg Minibatch loss for epoch 12: 9.409054\n",
      "   Avg Minibatch loss for epoch 13: 8.952783\n",
      "   Avg Minibatch loss for epoch 14: 8.505606\n",
      "   Avg Minibatch loss for epoch 15: 8.169319\n",
      "     ***   Training set accuracy: 51.84% ***\n",
      "     *** Validation set accuracy: 48.25% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.814906\n",
      "   Avg Minibatch loss for epoch 17: 7.569566\n",
      "   Avg Minibatch loss for epoch 18: 7.311466\n",
      "   Avg Minibatch loss for epoch 19: 7.071848\n",
      "   Avg Minibatch loss for epoch 20: 6.846348\n",
      "     ***   Training set accuracy: 55.59% ***\n",
      "     *** Validation set accuracy: 52.54% ***\n",
      "   Avg Minibatch loss for epoch 21: 6.621229\n",
      "   Avg Minibatch loss for epoch 22: 6.384359\n",
      "   Avg Minibatch loss for epoch 23: 6.159539\n",
      "   Avg Minibatch loss for epoch 24: 5.950614\n",
      "   Avg Minibatch loss for epoch 25: 5.734920\n",
      "     ***   Training set accuracy: 61.24% ***\n",
      "     *** Validation set accuracy: 57.97% ***\n",
      "   Avg Minibatch loss for epoch 26: 5.535678\n",
      "   Avg Minibatch loss for epoch 27: 5.322628\n",
      "   Avg Minibatch loss for epoch 28: 5.110889\n",
      "   Avg Minibatch loss for epoch 29: 4.912867\n",
      "   Avg Minibatch loss for epoch 30: 4.704469\n",
      "     ***   Training set accuracy: 68.25% ***\n",
      "     *** Validation set accuracy: 64.43% ***\n",
      "   Avg Minibatch loss for epoch 31: 4.502712\n",
      "   Avg Minibatch loss for epoch 32: 4.289893\n",
      "   Avg Minibatch loss for epoch 33: 4.096594\n",
      "   Avg Minibatch loss for epoch 34: 3.904587\n",
      "   Avg Minibatch loss for epoch 35: 3.702715\n",
      "     ***   Training set accuracy: 74.28% ***\n",
      "     *** Validation set accuracy: 70.28% ***\n",
      "   Avg Minibatch loss for epoch 36: 3.510497\n",
      "   Avg Minibatch loss for epoch 37: 3.320743\n",
      "   Avg Minibatch loss for epoch 38: 3.139063\n",
      "   Avg Minibatch loss for epoch 39: 2.962671\n",
      "   Avg Minibatch loss for epoch 40: 2.792333\n",
      "     ***   Training set accuracy: 78.91% ***\n",
      "     *** Validation set accuracy: 74.36% ***\n",
      "   Avg Minibatch loss for epoch 41: 2.633101\n",
      "   Avg Minibatch loss for epoch 42: 2.477575\n",
      "   Avg Minibatch loss for epoch 43: 2.322564\n",
      "   Avg Minibatch loss for epoch 44: 2.179261\n",
      "   Avg Minibatch loss for epoch 45: 2.037636\n",
      "     ***   Training set accuracy: 83.84% ***\n",
      "     *** Validation set accuracy: 77.94% ***\n",
      "   Avg Minibatch loss for epoch 46: 1.901325\n",
      "   Avg Minibatch loss for epoch 47: 1.769811\n",
      "   Avg Minibatch loss for epoch 48: 1.647499\n",
      "   Avg Minibatch loss for epoch 49: 1.527858\n",
      "   Avg Minibatch loss for epoch 50: 1.416914\n",
      "     ***   Training set accuracy: 89.03% ***\n",
      "     *** Validation set accuracy: 81.33% ***\n",
      "   Avg Minibatch loss for epoch 51: 1.309068\n",
      "   Avg Minibatch loss for epoch 52: 1.210343\n",
      "   Avg Minibatch loss for epoch 53: 1.115660\n",
      "   Avg Minibatch loss for epoch 54: 1.032389\n",
      "   Avg Minibatch loss for epoch 55: 0.955253\n",
      "     ***   Training set accuracy: 93.28% ***\n",
      "     *** Validation set accuracy: 83.42% ***\n",
      "   Avg Minibatch loss for epoch 56: 0.885457\n",
      "   Avg Minibatch loss for epoch 57: 0.820191\n",
      "   Avg Minibatch loss for epoch 58: 0.759805\n",
      "   Avg Minibatch loss for epoch 59: 0.708064\n",
      "   Avg Minibatch loss for epoch 60: 0.660329\n",
      "     ***   Training set accuracy: 96.21% ***\n",
      "     *** Validation set accuracy: 84.97% ***\n",
      "   Avg Minibatch loss for epoch 61: 0.615353\n",
      "   Avg Minibatch loss for epoch 62: 0.576860\n",
      "   Avg Minibatch loss for epoch 63: 0.541001\n",
      "   Avg Minibatch loss for epoch 64: 0.507598\n",
      "   Avg Minibatch loss for epoch 65: 0.478349\n",
      "     ***   Training set accuracy: 97.85% ***\n",
      "     *** Validation set accuracy: 85.40% ***\n",
      "   Avg Minibatch loss for epoch 66: 0.453849\n",
      "   Avg Minibatch loss for epoch 67: 0.429567\n",
      "   Avg Minibatch loss for epoch 68: 0.407559\n",
      "   Avg Minibatch loss for epoch 69: 0.389253\n",
      "   Avg Minibatch loss for epoch 70: 0.371823\n",
      "     ***   Training set accuracy: 98.61% ***\n",
      "     *** Validation set accuracy: 85.63% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.354683\n",
      "   Avg Minibatch loss for epoch 72: 0.337685\n",
      "   Avg Minibatch loss for epoch 73: 0.326318\n",
      "   Avg Minibatch loss for epoch 74: 0.312797\n",
      "   Avg Minibatch loss for epoch 75: 0.301147\n",
      "     ***   Training set accuracy: 99.11% ***\n",
      "     *** Validation set accuracy: 85.75% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.290767\n",
      "   Avg Minibatch loss for epoch 77: 0.280139\n",
      "   Avg Minibatch loss for epoch 78: 0.270616\n",
      "   Avg Minibatch loss for epoch 79: 0.262951\n",
      "   Avg Minibatch loss for epoch 80: 0.253533\n",
      "     ***   Training set accuracy: 99.35% ***\n",
      "     *** Validation set accuracy: 85.96% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.245614\n",
      "   Avg Minibatch loss for epoch 82: 0.241646\n",
      "   Avg Minibatch loss for epoch 83: 0.233283\n",
      "   Avg Minibatch loss for epoch 84: 0.226036\n",
      "   Avg Minibatch loss for epoch 85: 0.222215\n",
      "     ***   Training set accuracy: 99.47% ***\n",
      "     *** Validation set accuracy: 86.37% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.215210\n",
      "   Avg Minibatch loss for epoch 87: 0.212667\n",
      "   Avg Minibatch loss for epoch 88: 0.205462\n",
      "   Avg Minibatch loss for epoch 89: 0.202300\n",
      "   Avg Minibatch loss for epoch 90: 0.199212\n",
      "     ***   Training set accuracy: 99.48% ***\n",
      "     *** Validation set accuracy: 86.01% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.194397\n",
      "   Avg Minibatch loss for epoch 92: 0.190827\n",
      "   Avg Minibatch loss for epoch 93: 0.186949\n",
      "   Avg Minibatch loss for epoch 94: 0.185974\n",
      "   Avg Minibatch loss for epoch 95: 0.180610\n",
      "     ***   Training set accuracy: 99.39% ***\n",
      "     *** Validation set accuracy: 86.01% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.178710\n",
      "   Avg Minibatch loss for epoch 97: 0.174977\n",
      "   Avg Minibatch loss for epoch 98: 0.173000\n",
      "   Avg Minibatch loss for epoch 99: 0.171998\n",
      "   Avg Minibatch loss for epoch 100: 0.169187\n",
      "     ***   Training set accuracy: 99.63% ***\n",
      "     *** Validation set accuracy: 86.42% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.165897\n",
      "   Avg Minibatch loss for epoch 102: 0.165938\n",
      "   Avg Minibatch loss for epoch 103: 0.162100\n",
      "   Avg Minibatch loss for epoch 104: 0.161604\n",
      "   Avg Minibatch loss for epoch 105: 0.160397\n",
      "     ***   Training set accuracy: 99.58% ***\n",
      "     *** Validation set accuracy: 85.87% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.159193\n",
      "   Avg Minibatch loss for epoch 107: 0.156672\n",
      "   Avg Minibatch loss for epoch 108: 0.153458\n",
      "   Avg Minibatch loss for epoch 109: 0.153673\n",
      "   Avg Minibatch loss for epoch 110: 0.151736\n",
      "     ***   Training set accuracy: 99.59% ***\n",
      "     *** Validation set accuracy: 86.39% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.149622\n",
      "   Avg Minibatch loss for epoch 112: 0.149411\n",
      "   Avg Minibatch loss for epoch 113: 0.148139\n",
      "   Avg Minibatch loss for epoch 114: 0.147750\n",
      "   Avg Minibatch loss for epoch 115: 0.147861\n",
      "     ***   Training set accuracy: 99.64% ***\n",
      "     *** Validation set accuracy: 86.53% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.145761\n",
      "   Avg Minibatch loss for epoch 117: 0.144317\n",
      "   Avg Minibatch loss for epoch 118: 0.144999\n",
      "   Avg Minibatch loss for epoch 119: 0.142937\n",
      "   Avg Minibatch loss for epoch 120: 0.142880\n",
      "     ***   Training set accuracy: 99.48% ***\n",
      "     *** Validation set accuracy: 86.03% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.142049\n",
      "   Avg Minibatch loss for epoch 122: 0.140309\n",
      "   Avg Minibatch loss for epoch 123: 0.141742\n",
      "   Avg Minibatch loss for epoch 124: 0.138836\n",
      "\n",
      "   Final Training set accuracy: 99.66%\n",
      "   Final Validation set accuracy: 86.57%\n",
      "   Test set accuracy: 92.95%\n",
      "\n",
      "\n",
      "Run size 50000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2834.961763\n",
      "     ***   Training set accuracy: 78.79% ***\n",
      "     *** Validation set accuracy: 78.21% ***\n",
      "   Avg Minibatch loss for epoch 1: 713.251665\n",
      "   Avg Minibatch loss for epoch 2: 351.693132\n",
      "   Avg Minibatch loss for epoch 3: 179.415529\n",
      "   Avg Minibatch loss for epoch 4: 89.523829\n",
      "   Avg Minibatch loss for epoch 5: 47.767026\n",
      "     ***   Training set accuracy: 58.77% ***\n",
      "     *** Validation set accuracy: 57.62% ***\n",
      "   Avg Minibatch loss for epoch 6: 29.457859\n",
      "   Avg Minibatch loss for epoch 7: 20.684851\n",
      "   Avg Minibatch loss for epoch 8: 15.926966\n",
      "   Avg Minibatch loss for epoch 9: 13.288176\n",
      "   Avg Minibatch loss for epoch 10: 11.543341\n",
      "     ***   Training set accuracy: 46.04% ***\n",
      "     *** Validation set accuracy: 44.18% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.382103\n",
      "   Avg Minibatch loss for epoch 12: 9.570915\n",
      "   Avg Minibatch loss for epoch 13: 9.023358\n",
      "   Avg Minibatch loss for epoch 14: 8.574535\n",
      "   Avg Minibatch loss for epoch 15: 8.165526\n",
      "     ***   Training set accuracy: 46.08% ***\n",
      "     *** Validation set accuracy: 44.03% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.839724\n",
      "   Avg Minibatch loss for epoch 17: 7.536855\n",
      "   Avg Minibatch loss for epoch 18: 7.239456\n",
      "   Avg Minibatch loss for epoch 19: 6.964514\n",
      "   Avg Minibatch loss for epoch 20: 6.682847\n",
      "     ***   Training set accuracy: 53.06% ***\n",
      "     *** Validation set accuracy: 51.32% ***\n",
      "   Avg Minibatch loss for epoch 21: 6.407989\n",
      "   Avg Minibatch loss for epoch 22: 6.128104\n",
      "   Avg Minibatch loss for epoch 23: 5.828880\n",
      "   Avg Minibatch loss for epoch 24: 5.533221\n",
      "   Avg Minibatch loss for epoch 25: 5.259465\n",
      "     ***   Training set accuracy: 63.42% ***\n",
      "     *** Validation set accuracy: 61.53% ***\n",
      "   Avg Minibatch loss for epoch 26: 4.959748\n",
      "   Avg Minibatch loss for epoch 27: 4.672470\n",
      "   Avg Minibatch loss for epoch 28: 4.377591\n",
      "   Avg Minibatch loss for epoch 29: 4.077064\n",
      "   Avg Minibatch loss for epoch 30: 3.788825\n",
      "     ***   Training set accuracy: 72.69% ***\n",
      "     *** Validation set accuracy: 70.58% ***\n",
      "   Avg Minibatch loss for epoch 31: 3.515391\n",
      "   Avg Minibatch loss for epoch 32: 3.232145\n",
      "   Avg Minibatch loss for epoch 33: 2.959295\n",
      "   Avg Minibatch loss for epoch 34: 2.702233\n",
      "   Avg Minibatch loss for epoch 35: 2.452381\n",
      "     ***   Training set accuracy: 81.54% ***\n",
      "     *** Validation set accuracy: 79.05% ***\n",
      "   Avg Minibatch loss for epoch 36: 2.217713\n",
      "   Avg Minibatch loss for epoch 37: 1.992944\n",
      "   Avg Minibatch loss for epoch 38: 1.793967\n",
      "   Avg Minibatch loss for epoch 39: 1.610027\n",
      "   Avg Minibatch loss for epoch 40: 1.441359\n",
      "     ***   Training set accuracy: 87.45% ***\n",
      "     *** Validation set accuracy: 83.59% ***\n",
      "   Avg Minibatch loss for epoch 41: 1.295880\n",
      "   Avg Minibatch loss for epoch 42: 1.167887\n",
      "   Avg Minibatch loss for epoch 43: 1.060652\n",
      "   Avg Minibatch loss for epoch 44: 0.965572\n",
      "   Avg Minibatch loss for epoch 45: 0.882656\n",
      "     ***   Training set accuracy: 91.91% ***\n",
      "     *** Validation set accuracy: 85.99% ***\n",
      "   Avg Minibatch loss for epoch 46: 0.812343\n",
      "   Avg Minibatch loss for epoch 47: 0.751833\n",
      "   Avg Minibatch loss for epoch 48: 0.699283\n",
      "   Avg Minibatch loss for epoch 49: 0.652408\n",
      "   Avg Minibatch loss for epoch 50: 0.610829\n",
      "     ***   Training set accuracy: 94.48% ***\n",
      "     *** Validation set accuracy: 86.98% ***\n",
      "   Avg Minibatch loss for epoch 51: 0.575917\n",
      "   Avg Minibatch loss for epoch 52: 0.544652\n",
      "   Avg Minibatch loss for epoch 53: 0.515861\n",
      "   Avg Minibatch loss for epoch 54: 0.489457\n",
      "   Avg Minibatch loss for epoch 55: 0.466785\n",
      "     ***   Training set accuracy: 96.20% ***\n",
      "     *** Validation set accuracy: 87.51% ***\n",
      "   Avg Minibatch loss for epoch 56: 0.447428\n",
      "   Avg Minibatch loss for epoch 57: 0.432530\n",
      "   Avg Minibatch loss for epoch 58: 0.412856\n",
      "   Avg Minibatch loss for epoch 59: 0.399061\n",
      "   Avg Minibatch loss for epoch 60: 0.382940\n",
      "     ***   Training set accuracy: 97.21% ***\n",
      "     *** Validation set accuracy: 87.24% ***\n",
      "   Avg Minibatch loss for epoch 61: 0.370953\n",
      "   Avg Minibatch loss for epoch 62: 0.360682\n",
      "   Avg Minibatch loss for epoch 63: 0.347415\n",
      "   Avg Minibatch loss for epoch 64: 0.339082\n",
      "   Avg Minibatch loss for epoch 65: 0.329096\n",
      "     ***   Training set accuracy: 97.91% ***\n",
      "     *** Validation set accuracy: 87.64% ***\n",
      "   Avg Minibatch loss for epoch 66: 0.325154\n",
      "   Avg Minibatch loss for epoch 67: 0.313499\n",
      "   Avg Minibatch loss for epoch 68: 0.308347\n",
      "   Avg Minibatch loss for epoch 69: 0.300699\n",
      "   Avg Minibatch loss for epoch 70: 0.295339\n",
      "     ***   Training set accuracy: 98.40% ***\n",
      "     *** Validation set accuracy: 87.55% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.289472\n",
      "   Avg Minibatch loss for epoch 72: 0.284096\n",
      "   Avg Minibatch loss for epoch 73: 0.278665\n",
      "   Avg Minibatch loss for epoch 74: 0.275429\n",
      "   Avg Minibatch loss for epoch 75: 0.267989\n",
      "     ***   Training set accuracy: 98.49% ***\n",
      "     *** Validation set accuracy: 87.61% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.264736\n",
      "   Avg Minibatch loss for epoch 77: 0.261758\n",
      "   Avg Minibatch loss for epoch 78: 0.258385\n",
      "   Avg Minibatch loss for epoch 79: 0.252124\n",
      "   Avg Minibatch loss for epoch 80: 0.252070\n",
      "     ***   Training set accuracy: 98.86% ***\n",
      "     *** Validation set accuracy: 87.89% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.248010\n",
      "   Avg Minibatch loss for epoch 82: 0.245154\n",
      "   Avg Minibatch loss for epoch 83: 0.243589\n",
      "   Avg Minibatch loss for epoch 84: 0.239295\n",
      "   Avg Minibatch loss for epoch 85: 0.237868\n",
      "     ***   Training set accuracy: 98.95% ***\n",
      "     *** Validation set accuracy: 88.11% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.237416\n",
      "   Avg Minibatch loss for epoch 87: 0.233586\n",
      "   Avg Minibatch loss for epoch 88: 0.230326\n",
      "   Avg Minibatch loss for epoch 89: 0.230727\n",
      "   Avg Minibatch loss for epoch 90: 0.227499\n",
      "     ***   Training set accuracy: 99.11% ***\n",
      "     *** Validation set accuracy: 88.17% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.226468\n",
      "   Avg Minibatch loss for epoch 92: 0.225102\n",
      "   Avg Minibatch loss for epoch 93: 0.224230\n",
      "   Avg Minibatch loss for epoch 94: 0.219990\n",
      "   Avg Minibatch loss for epoch 95: 0.220902\n",
      "     ***   Training set accuracy: 99.03% ***\n",
      "     *** Validation set accuracy: 87.95% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.218029\n",
      "   Avg Minibatch loss for epoch 97: 0.216472\n",
      "   Avg Minibatch loss for epoch 98: 0.216267\n",
      "   Avg Minibatch loss for epoch 99: 0.214737\n",
      "   Avg Minibatch loss for epoch 100: 0.213291\n",
      "     ***   Training set accuracy: 99.22% ***\n",
      "     *** Validation set accuracy: 88.06% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.211480\n",
      "   Avg Minibatch loss for epoch 102: 0.210204\n",
      "   Avg Minibatch loss for epoch 103: 0.210416\n",
      "   Avg Minibatch loss for epoch 104: 0.209286\n",
      "   Avg Minibatch loss for epoch 105: 0.208734\n",
      "     ***   Training set accuracy: 99.20% ***\n",
      "     *** Validation set accuracy: 88.09% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.206750\n",
      "   Avg Minibatch loss for epoch 107: 0.204670\n",
      "   Avg Minibatch loss for epoch 108: 0.203988\n",
      "   Avg Minibatch loss for epoch 109: 0.205342\n",
      "   Avg Minibatch loss for epoch 110: 0.203547\n",
      "     ***   Training set accuracy: 99.24% ***\n",
      "     *** Validation set accuracy: 87.73% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.203044\n",
      "   Avg Minibatch loss for epoch 112: 0.202500\n",
      "   Avg Minibatch loss for epoch 113: 0.201558\n",
      "   Avg Minibatch loss for epoch 114: 0.199736\n",
      "   Avg Minibatch loss for epoch 115: 0.200927\n",
      "     ***   Training set accuracy: 99.24% ***\n",
      "     *** Validation set accuracy: 88.12% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.201241\n",
      "   Avg Minibatch loss for epoch 117: 0.199178\n",
      "   Avg Minibatch loss for epoch 118: 0.200333\n",
      "   Avg Minibatch loss for epoch 119: 0.196643\n",
      "   Avg Minibatch loss for epoch 120: 0.198644\n",
      "     ***   Training set accuracy: 99.26% ***\n",
      "     *** Validation set accuracy: 88.00% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.196546\n",
      "   Avg Minibatch loss for epoch 122: 0.196265\n",
      "   Avg Minibatch loss for epoch 123: 0.196001\n",
      "   Avg Minibatch loss for epoch 124: 0.196216\n",
      "\n",
      "   Final Training set accuracy: 99.29%\n",
      "   Final Validation set accuracy: 87.96%\n",
      "   Test set accuracy: 93.89%\n",
      "\n",
      "\n",
      "Run size 250000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2708.149490\n",
      "     ***   Training set accuracy: 77.54% ***\n",
      "     *** Validation set accuracy: 76.99% ***\n",
      "   Avg Minibatch loss for epoch 1: 697.779377\n",
      "   Avg Minibatch loss for epoch 2: 330.616968\n",
      "   Avg Minibatch loss for epoch 3: 154.736419\n",
      "   Avg Minibatch loss for epoch 4: 76.388444\n",
      "   Avg Minibatch loss for epoch 5: 44.103266\n",
      "     ***   Training set accuracy: 51.23% ***\n",
      "     *** Validation set accuracy: 50.49% ***\n",
      "   Avg Minibatch loss for epoch 6: 28.937225\n",
      "   Avg Minibatch loss for epoch 7: 21.487946\n",
      "   Avg Minibatch loss for epoch 8: 16.858850\n",
      "   Avg Minibatch loss for epoch 9: 14.153276\n",
      "   Avg Minibatch loss for epoch 10: 12.377839\n",
      "     ***   Training set accuracy: 37.84% ***\n",
      "     *** Validation set accuracy: 37.13% ***\n",
      "   Avg Minibatch loss for epoch 11: 11.126322\n",
      "   Avg Minibatch loss for epoch 12: 10.187517\n",
      "   Avg Minibatch loss for epoch 13: 9.570181\n",
      "   Avg Minibatch loss for epoch 14: 8.974283\n",
      "   Avg Minibatch loss for epoch 15: 8.528265\n",
      "     ***   Training set accuracy: 37.07% ***\n",
      "     *** Validation set accuracy: 36.60% ***\n",
      "   Avg Minibatch loss for epoch 16: 8.152041\n",
      "   Avg Minibatch loss for epoch 17: 7.808588\n",
      "   Avg Minibatch loss for epoch 18: 7.445186\n",
      "   Avg Minibatch loss for epoch 19: 7.112668\n",
      "   Avg Minibatch loss for epoch 20: 6.789976\n",
      "     ***   Training set accuracy: 44.15% ***\n",
      "     *** Validation set accuracy: 43.94% ***\n",
      "   Avg Minibatch loss for epoch 21: 6.463903\n",
      "   Avg Minibatch loss for epoch 22: 6.142713\n",
      "   Avg Minibatch loss for epoch 23: 5.821611\n",
      "   Avg Minibatch loss for epoch 24: 5.487526\n",
      "   Avg Minibatch loss for epoch 25: 5.141603\n",
      "     ***   Training set accuracy: 59.42% ***\n",
      "     *** Validation set accuracy: 59.30% ***\n",
      "   Avg Minibatch loss for epoch 26: 4.801718\n",
      "   Avg Minibatch loss for epoch 27: 4.487150\n",
      "   Avg Minibatch loss for epoch 28: 4.162746\n",
      "   Avg Minibatch loss for epoch 29: 3.877463\n",
      "   Avg Minibatch loss for epoch 30: 3.592125\n",
      "     ***   Training set accuracy: 70.45% ***\n",
      "     *** Validation set accuracy: 70.11% ***\n",
      "   Avg Minibatch loss for epoch 31: 3.332124\n",
      "   Avg Minibatch loss for epoch 32: 3.086492\n",
      "   Avg Minibatch loss for epoch 33: 2.846593\n",
      "   Avg Minibatch loss for epoch 34: 2.624778\n",
      "   Avg Minibatch loss for epoch 35: 2.413330\n",
      "     ***   Training set accuracy: 78.44% ***\n",
      "     *** Validation set accuracy: 77.84% ***\n",
      "   Avg Minibatch loss for epoch 36: 2.212474\n",
      "   Avg Minibatch loss for epoch 37: 2.024471\n",
      "   Avg Minibatch loss for epoch 38: 1.855970\n",
      "   Avg Minibatch loss for epoch 39: 1.697271\n",
      "   Avg Minibatch loss for epoch 40: 1.553070\n",
      "     ***   Training set accuracy: 83.43% ***\n",
      "     *** Validation set accuracy: 82.32% ***\n",
      "   Avg Minibatch loss for epoch 41: 1.423782\n",
      "   Avg Minibatch loss for epoch 42: 1.303964\n",
      "   Avg Minibatch loss for epoch 43: 1.196390\n",
      "   Avg Minibatch loss for epoch 44: 1.097064\n",
      "   Avg Minibatch loss for epoch 45: 1.012294\n",
      "     ***   Training set accuracy: 87.03% ***\n",
      "     *** Validation set accuracy: 86.03% ***\n",
      "   Avg Minibatch loss for epoch 46: 0.934976\n",
      "   Avg Minibatch loss for epoch 47: 0.866767\n",
      "   Avg Minibatch loss for epoch 48: 0.804060\n",
      "   Avg Minibatch loss for epoch 49: 0.751352\n",
      "   Avg Minibatch loss for epoch 50: 0.703599\n",
      "     ***   Training set accuracy: 89.45% ***\n",
      "     *** Validation set accuracy: 88.26% ***\n",
      "   Avg Minibatch loss for epoch 51: 0.663317\n",
      "   Avg Minibatch loss for epoch 52: 0.626343\n",
      "   Avg Minibatch loss for epoch 53: 0.596400\n",
      "   Avg Minibatch loss for epoch 54: 0.568604\n",
      "   Avg Minibatch loss for epoch 55: 0.545909\n",
      "     ***   Training set accuracy: 90.70% ***\n",
      "     *** Validation set accuracy: 89.13% ***\n",
      "   Avg Minibatch loss for epoch 56: 0.525932\n",
      "   Avg Minibatch loss for epoch 57: 0.508090\n",
      "   Avg Minibatch loss for epoch 58: 0.492780\n",
      "   Avg Minibatch loss for epoch 59: 0.479362\n",
      "   Avg Minibatch loss for epoch 60: 0.466799\n",
      "     ***   Training set accuracy: 91.56% ***\n",
      "     *** Validation set accuracy: 89.54% ***\n",
      "   Avg Minibatch loss for epoch 61: 0.456141\n",
      "   Avg Minibatch loss for epoch 62: 0.447965\n",
      "   Avg Minibatch loss for epoch 63: 0.439027\n",
      "   Avg Minibatch loss for epoch 64: 0.431820\n",
      "   Avg Minibatch loss for epoch 65: 0.424193\n",
      "     ***   Training set accuracy: 91.99% ***\n",
      "     *** Validation set accuracy: 90.08% ***\n",
      "   Avg Minibatch loss for epoch 66: 0.420143\n",
      "   Avg Minibatch loss for epoch 67: 0.411859\n",
      "   Avg Minibatch loss for epoch 68: 0.409309\n",
      "   Avg Minibatch loss for epoch 69: 0.404691\n",
      "   Avg Minibatch loss for epoch 70: 0.400163\n",
      "     ***   Training set accuracy: 92.27% ***\n",
      "     *** Validation set accuracy: 90.19% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.396010\n",
      "   Avg Minibatch loss for epoch 72: 0.394687\n",
      "   Avg Minibatch loss for epoch 73: 0.391260\n",
      "   Avg Minibatch loss for epoch 74: 0.387987\n",
      "   Avg Minibatch loss for epoch 75: 0.385208\n",
      "     ***   Training set accuracy: 92.49% ***\n",
      "     *** Validation set accuracy: 90.15% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.383729\n",
      "   Avg Minibatch loss for epoch 77: 0.380652\n",
      "   Avg Minibatch loss for epoch 78: 0.377478\n",
      "   Avg Minibatch loss for epoch 79: 0.377606\n",
      "   Avg Minibatch loss for epoch 80: 0.375662\n",
      "     ***   Training set accuracy: 92.81% ***\n",
      "     *** Validation set accuracy: 90.30% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.373347\n",
      "   Avg Minibatch loss for epoch 82: 0.372710\n",
      "   Avg Minibatch loss for epoch 83: 0.371096\n",
      "   Avg Minibatch loss for epoch 84: 0.367691\n",
      "   Avg Minibatch loss for epoch 85: 0.366673\n",
      "     ***   Training set accuracy: 93.06% ***\n",
      "     *** Validation set accuracy: 90.43% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.365063\n",
      "   Avg Minibatch loss for epoch 87: 0.366323\n",
      "   Avg Minibatch loss for epoch 88: 0.361839\n",
      "   Avg Minibatch loss for epoch 89: 0.362367\n",
      "   Avg Minibatch loss for epoch 90: 0.362590\n",
      "     ***   Training set accuracy: 93.19% ***\n",
      "     *** Validation set accuracy: 90.59% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.360468\n",
      "   Avg Minibatch loss for epoch 92: 0.359054\n",
      "   Avg Minibatch loss for epoch 93: 0.358537\n",
      "   Avg Minibatch loss for epoch 94: 0.356742\n",
      "   Avg Minibatch loss for epoch 95: 0.358085\n",
      "     ***   Training set accuracy: 93.35% ***\n",
      "     *** Validation set accuracy: 90.30% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.355888\n",
      "   Avg Minibatch loss for epoch 97: 0.357328\n",
      "   Avg Minibatch loss for epoch 98: 0.355450\n",
      "   Avg Minibatch loss for epoch 99: 0.354520\n",
      "   Avg Minibatch loss for epoch 100: 0.354025\n",
      "     ***   Training set accuracy: 93.43% ***\n",
      "     *** Validation set accuracy: 90.41% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.352856\n",
      "   Avg Minibatch loss for epoch 102: 0.352463\n",
      "   Avg Minibatch loss for epoch 103: 0.352167\n",
      "   Avg Minibatch loss for epoch 104: 0.351063\n",
      "   Avg Minibatch loss for epoch 105: 0.351429\n",
      "     ***   Training set accuracy: 93.57% ***\n",
      "     *** Validation set accuracy: 90.55% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.349898\n",
      "   Avg Minibatch loss for epoch 107: 0.349489\n",
      "   Avg Minibatch loss for epoch 108: 0.349839\n",
      "   Avg Minibatch loss for epoch 109: 0.349358\n",
      "   Avg Minibatch loss for epoch 110: 0.348526\n",
      "     ***   Training set accuracy: 93.77% ***\n",
      "     *** Validation set accuracy: 90.53% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.346530\n",
      "   Avg Minibatch loss for epoch 112: 0.348569\n",
      "   Avg Minibatch loss for epoch 113: 0.345817\n",
      "   Avg Minibatch loss for epoch 114: 0.345011\n",
      "   Avg Minibatch loss for epoch 115: 0.347049\n",
      "     ***   Training set accuracy: 93.88% ***\n",
      "     *** Validation set accuracy: 90.79% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.347554\n",
      "   Avg Minibatch loss for epoch 117: 0.344814\n",
      "   Avg Minibatch loss for epoch 118: 0.344852\n",
      "   Avg Minibatch loss for epoch 119: 0.343968\n",
      "   Avg Minibatch loss for epoch 120: 0.344118\n",
      "     ***   Training set accuracy: 94.03% ***\n",
      "     *** Validation set accuracy: 90.49% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.343778\n",
      "   Avg Minibatch loss for epoch 122: 0.343927\n",
      "   Avg Minibatch loss for epoch 123: 0.342761\n",
      "   Avg Minibatch loss for epoch 124: 0.341772\n",
      "\n",
      "   Final Training set accuracy: 93.95%\n",
      "   Final Validation set accuracy: 90.49%\n",
      "   Test set accuracy: 96.07%\n",
      "\n",
      "\n",
      "Run size 100000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2899.677454\n",
      "     ***   Training set accuracy: 77.97% ***\n",
      "     *** Validation set accuracy: 77.21% ***\n",
      "   Avg Minibatch loss for epoch 1: 721.810955\n",
      "   Avg Minibatch loss for epoch 2: 347.224290\n",
      "   Avg Minibatch loss for epoch 3: 170.617455\n",
      "   Avg Minibatch loss for epoch 4: 82.859618\n",
      "   Avg Minibatch loss for epoch 5: 45.192215\n",
      "     ***   Training set accuracy: 55.03% ***\n",
      "     *** Validation set accuracy: 54.02% ***\n",
      "   Avg Minibatch loss for epoch 6: 28.392542\n",
      "   Avg Minibatch loss for epoch 7: 20.471104\n",
      "   Avg Minibatch loss for epoch 8: 15.972011\n",
      "   Avg Minibatch loss for epoch 9: 13.178249\n",
      "   Avg Minibatch loss for epoch 10: 11.497981\n",
      "     ***   Training set accuracy: 42.23% ***\n",
      "     *** Validation set accuracy: 41.06% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.316970\n",
      "   Avg Minibatch loss for epoch 12: 9.544434\n",
      "   Avg Minibatch loss for epoch 13: 8.882953\n",
      "   Avg Minibatch loss for epoch 14: 8.344900\n",
      "   Avg Minibatch loss for epoch 15: 7.950487\n",
      "     ***   Training set accuracy: 41.58% ***\n",
      "     *** Validation set accuracy: 40.79% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.591331\n",
      "   Avg Minibatch loss for epoch 17: 7.289694\n",
      "   Avg Minibatch loss for epoch 18: 6.989624\n",
      "   Avg Minibatch loss for epoch 19: 6.686685\n",
      "   Avg Minibatch loss for epoch 20: 6.388678\n",
      "     ***   Training set accuracy: 52.53% ***\n",
      "     *** Validation set accuracy: 51.99% ***\n",
      "   Avg Minibatch loss for epoch 21: 6.110846\n",
      "   Avg Minibatch loss for epoch 22: 5.811808\n",
      "   Avg Minibatch loss for epoch 23: 5.534731\n",
      "   Avg Minibatch loss for epoch 24: 5.241653\n",
      "   Avg Minibatch loss for epoch 25: 4.956919\n",
      "     ***   Training set accuracy: 63.62% ***\n",
      "     *** Validation set accuracy: 62.82% ***\n",
      "   Avg Minibatch loss for epoch 26: 4.671323\n",
      "   Avg Minibatch loss for epoch 27: 4.388700\n",
      "   Avg Minibatch loss for epoch 28: 4.114545\n",
      "   Avg Minibatch loss for epoch 29: 3.850116\n",
      "   Avg Minibatch loss for epoch 30: 3.588142\n",
      "     ***   Training set accuracy: 73.26% ***\n",
      "     *** Validation set accuracy: 71.95% ***\n",
      "   Avg Minibatch loss for epoch 31: 3.322300\n",
      "   Avg Minibatch loss for epoch 32: 3.068442\n",
      "   Avg Minibatch loss for epoch 33: 2.829277\n",
      "   Avg Minibatch loss for epoch 34: 2.603082\n",
      "   Avg Minibatch loss for epoch 35: 2.385592\n",
      "     ***   Training set accuracy: 79.61% ***\n",
      "     *** Validation set accuracy: 78.83% ***\n",
      "   Avg Minibatch loss for epoch 36: 2.183027\n",
      "   Avg Minibatch loss for epoch 37: 1.996078\n",
      "   Avg Minibatch loss for epoch 38: 1.822997\n",
      "   Avg Minibatch loss for epoch 39: 1.662706\n",
      "   Avg Minibatch loss for epoch 40: 1.504247\n",
      "     ***   Training set accuracy: 85.02% ***\n",
      "     *** Validation set accuracy: 83.68% ***\n",
      "   Avg Minibatch loss for epoch 41: 1.362769\n",
      "   Avg Minibatch loss for epoch 42: 1.241911\n",
      "   Avg Minibatch loss for epoch 43: 1.133770\n",
      "   Avg Minibatch loss for epoch 44: 1.035045\n",
      "   Avg Minibatch loss for epoch 45: 0.950700\n",
      "     ***   Training set accuracy: 88.62% ***\n",
      "     *** Validation set accuracy: 86.28% ***\n",
      "   Avg Minibatch loss for epoch 46: 0.873175\n",
      "   Avg Minibatch loss for epoch 47: 0.807904\n",
      "   Avg Minibatch loss for epoch 48: 0.752892\n",
      "   Avg Minibatch loss for epoch 49: 0.702075\n",
      "   Avg Minibatch loss for epoch 50: 0.657796\n",
      "     ***   Training set accuracy: 90.94% ***\n",
      "     *** Validation set accuracy: 87.74% ***\n",
      "   Avg Minibatch loss for epoch 51: 0.622054\n",
      "   Avg Minibatch loss for epoch 52: 0.588214\n",
      "   Avg Minibatch loss for epoch 53: 0.560073\n",
      "   Avg Minibatch loss for epoch 54: 0.534218\n",
      "   Avg Minibatch loss for epoch 55: 0.511159\n",
      "     ***   Training set accuracy: 92.35% ***\n",
      "     *** Validation set accuracy: 88.77% ***\n",
      "   Avg Minibatch loss for epoch 56: 0.492435\n",
      "   Avg Minibatch loss for epoch 57: 0.474704\n",
      "   Avg Minibatch loss for epoch 58: 0.460922\n",
      "   Avg Minibatch loss for epoch 59: 0.447187\n",
      "   Avg Minibatch loss for epoch 60: 0.435405\n",
      "     ***   Training set accuracy: 93.44% ***\n",
      "     *** Validation set accuracy: 89.12% ***\n",
      "   Avg Minibatch loss for epoch 61: 0.424377\n",
      "   Avg Minibatch loss for epoch 62: 0.414573\n",
      "   Avg Minibatch loss for epoch 63: 0.406160\n",
      "   Avg Minibatch loss for epoch 64: 0.397492\n",
      "   Avg Minibatch loss for epoch 65: 0.390282\n",
      "     ***   Training set accuracy: 94.24% ***\n",
      "     *** Validation set accuracy: 89.27% ***\n",
      "   Avg Minibatch loss for epoch 66: 0.384958\n",
      "   Avg Minibatch loss for epoch 67: 0.376518\n",
      "   Avg Minibatch loss for epoch 68: 0.372235\n",
      "   Avg Minibatch loss for epoch 69: 0.364890\n",
      "   Avg Minibatch loss for epoch 70: 0.361303\n",
      "     ***   Training set accuracy: 94.87% ***\n",
      "     *** Validation set accuracy: 89.34% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.358171\n",
      "   Avg Minibatch loss for epoch 72: 0.351556\n",
      "   Avg Minibatch loss for epoch 73: 0.348847\n",
      "   Avg Minibatch loss for epoch 74: 0.345101\n",
      "   Avg Minibatch loss for epoch 75: 0.342219\n",
      "     ***   Training set accuracy: 95.28% ***\n",
      "     *** Validation set accuracy: 89.23% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.338821\n",
      "   Avg Minibatch loss for epoch 77: 0.336015\n",
      "   Avg Minibatch loss for epoch 78: 0.334054\n",
      "   Avg Minibatch loss for epoch 79: 0.330556\n",
      "   Avg Minibatch loss for epoch 80: 0.328472\n",
      "     ***   Training set accuracy: 95.62% ***\n",
      "     *** Validation set accuracy: 89.51% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.328419\n",
      "   Avg Minibatch loss for epoch 82: 0.324673\n",
      "   Avg Minibatch loss for epoch 83: 0.322295\n",
      "   Avg Minibatch loss for epoch 84: 0.321896\n",
      "   Avg Minibatch loss for epoch 85: 0.317444\n",
      "     ***   Training set accuracy: 95.90% ***\n",
      "     *** Validation set accuracy: 89.23% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.315577\n",
      "   Avg Minibatch loss for epoch 87: 0.315382\n",
      "   Avg Minibatch loss for epoch 88: 0.313513\n",
      "   Avg Minibatch loss for epoch 89: 0.311455\n",
      "   Avg Minibatch loss for epoch 90: 0.310802\n",
      "     ***   Training set accuracy: 96.29% ***\n",
      "     *** Validation set accuracy: 89.35% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.309369\n",
      "   Avg Minibatch loss for epoch 92: 0.307157\n",
      "   Avg Minibatch loss for epoch 93: 0.305915\n",
      "   Avg Minibatch loss for epoch 94: 0.304098\n",
      "   Avg Minibatch loss for epoch 95: 0.304661\n",
      "     ***   Training set accuracy: 96.42% ***\n",
      "     *** Validation set accuracy: 89.69% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.300889\n",
      "   Avg Minibatch loss for epoch 97: 0.300310\n",
      "   Avg Minibatch loss for epoch 98: 0.299788\n",
      "   Avg Minibatch loss for epoch 99: 0.298377\n",
      "   Avg Minibatch loss for epoch 100: 0.298487\n",
      "     ***   Training set accuracy: 96.65% ***\n",
      "     *** Validation set accuracy: 89.55% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.297572\n",
      "   Avg Minibatch loss for epoch 102: 0.296920\n",
      "   Avg Minibatch loss for epoch 103: 0.292592\n",
      "   Avg Minibatch loss for epoch 104: 0.294256\n",
      "   Avg Minibatch loss for epoch 105: 0.291290\n",
      "     ***   Training set accuracy: 96.81% ***\n",
      "     *** Validation set accuracy: 89.48% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.292901\n",
      "   Avg Minibatch loss for epoch 107: 0.289612\n",
      "   Avg Minibatch loss for epoch 108: 0.290678\n",
      "   Avg Minibatch loss for epoch 109: 0.288078\n",
      "   Avg Minibatch loss for epoch 110: 0.288924\n",
      "     ***   Training set accuracy: 97.03% ***\n",
      "     *** Validation set accuracy: 89.71% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.288063\n",
      "   Avg Minibatch loss for epoch 112: 0.287784\n",
      "   Avg Minibatch loss for epoch 113: 0.287608\n",
      "   Avg Minibatch loss for epoch 114: 0.284908\n",
      "   Avg Minibatch loss for epoch 115: 0.285137\n",
      "     ***   Training set accuracy: 97.10% ***\n",
      "     *** Validation set accuracy: 89.95% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.285433\n",
      "   Avg Minibatch loss for epoch 117: 0.283698\n",
      "   Avg Minibatch loss for epoch 118: 0.283012\n",
      "   Avg Minibatch loss for epoch 119: 0.283171\n",
      "   Avg Minibatch loss for epoch 120: 0.281720\n",
      "     ***   Training set accuracy: 97.24% ***\n",
      "     *** Validation set accuracy: 89.67% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.282893\n",
      "   Avg Minibatch loss for epoch 122: 0.280157\n",
      "   Avg Minibatch loss for epoch 123: 0.279866\n",
      "   Avg Minibatch loss for epoch 124: 0.280562\n",
      "\n",
      "   Final Training set accuracy: 97.24%\n",
      "   Final Validation set accuracy: 89.57%\n",
      "   Test set accuracy: 95.36%\n",
      "\n",
      "\n",
      "Run size 200000 initialized\n",
      "   Avg Minibatch loss for epoch 0: 2984.639114\n",
      "     ***   Training set accuracy: 77.96% ***\n",
      "     *** Validation set accuracy: 77.31% ***\n",
      "   Avg Minibatch loss for epoch 1: 737.999261\n",
      "   Avg Minibatch loss for epoch 2: 362.714630\n",
      "   Avg Minibatch loss for epoch 3: 178.351764\n",
      "   Avg Minibatch loss for epoch 4: 85.521521\n",
      "   Avg Minibatch loss for epoch 5: 46.348917\n",
      "     ***   Training set accuracy: 54.00% ***\n",
      "     *** Validation set accuracy: 53.42% ***\n",
      "   Avg Minibatch loss for epoch 6: 29.645417\n",
      "   Avg Minibatch loss for epoch 7: 21.042495\n",
      "   Avg Minibatch loss for epoch 8: 16.224697\n",
      "   Avg Minibatch loss for epoch 9: 13.512273\n",
      "   Avg Minibatch loss for epoch 10: 11.711469\n",
      "     ***   Training set accuracy: 40.48% ***\n",
      "     *** Validation set accuracy: 39.96% ***\n",
      "   Avg Minibatch loss for epoch 11: 10.527388\n",
      "   Avg Minibatch loss for epoch 12: 9.715376\n",
      "   Avg Minibatch loss for epoch 13: 9.039747\n",
      "   Avg Minibatch loss for epoch 14: 8.515599\n",
      "   Avg Minibatch loss for epoch 15: 8.056392\n",
      "     ***   Training set accuracy: 43.45% ***\n",
      "     *** Validation set accuracy: 42.66% ***\n",
      "   Avg Minibatch loss for epoch 16: 7.678923\n",
      "   Avg Minibatch loss for epoch 17: 7.315171\n",
      "   Avg Minibatch loss for epoch 18: 6.930286\n",
      "   Avg Minibatch loss for epoch 19: 6.568612\n",
      "   Avg Minibatch loss for epoch 20: 6.176164\n",
      "     ***   Training set accuracy: 57.47% ***\n",
      "     *** Validation set accuracy: 56.70% ***\n",
      "   Avg Minibatch loss for epoch 21: 5.793217\n",
      "   Avg Minibatch loss for epoch 22: 5.389846\n",
      "   Avg Minibatch loss for epoch 23: 4.987654\n",
      "   Avg Minibatch loss for epoch 24: 4.587855\n",
      "   Avg Minibatch loss for epoch 25: 4.163602\n",
      "     ***   Training set accuracy: 71.66% ***\n",
      "     *** Validation set accuracy: 70.87% ***\n",
      "   Avg Minibatch loss for epoch 26: 3.767840\n",
      "   Avg Minibatch loss for epoch 27: 3.378347\n",
      "   Avg Minibatch loss for epoch 28: 3.004748\n",
      "   Avg Minibatch loss for epoch 29: 2.649561\n",
      "   Avg Minibatch loss for epoch 30: 2.307066\n",
      "     ***   Training set accuracy: 81.67% ***\n",
      "     *** Validation set accuracy: 80.81% ***\n",
      "   Avg Minibatch loss for epoch 31: 1.997522\n",
      "   Avg Minibatch loss for epoch 32: 1.725185\n",
      "   Avg Minibatch loss for epoch 33: 1.496315\n",
      "   Avg Minibatch loss for epoch 34: 1.312434\n",
      "   Avg Minibatch loss for epoch 35: 1.159737\n",
      "     ***   Training set accuracy: 86.78% ***\n",
      "     *** Validation set accuracy: 85.54% ***\n",
      "   Avg Minibatch loss for epoch 36: 1.036694\n",
      "   Avg Minibatch loss for epoch 37: 0.936158\n",
      "   Avg Minibatch loss for epoch 38: 0.854351\n",
      "   Avg Minibatch loss for epoch 39: 0.782899\n",
      "   Avg Minibatch loss for epoch 40: 0.725016\n",
      "     ***   Training set accuracy: 89.54% ***\n",
      "     *** Validation set accuracy: 87.93% ***\n",
      "   Avg Minibatch loss for epoch 41: 0.675649\n",
      "   Avg Minibatch loss for epoch 42: 0.636972\n",
      "   Avg Minibatch loss for epoch 43: 0.603143\n",
      "   Avg Minibatch loss for epoch 44: 0.573480\n",
      "   Avg Minibatch loss for epoch 45: 0.548893\n",
      "     ***   Training set accuracy: 90.79% ***\n",
      "     *** Validation set accuracy: 89.01% ***\n",
      "   Avg Minibatch loss for epoch 46: 0.527333\n",
      "   Avg Minibatch loss for epoch 47: 0.507989\n",
      "   Avg Minibatch loss for epoch 48: 0.492695\n",
      "   Avg Minibatch loss for epoch 49: 0.478471\n",
      "   Avg Minibatch loss for epoch 50: 0.466010\n",
      "     ***   Training set accuracy: 91.61% ***\n",
      "     *** Validation set accuracy: 89.60% ***\n",
      "   Avg Minibatch loss for epoch 51: 0.457701\n",
      "   Avg Minibatch loss for epoch 52: 0.446481\n",
      "   Avg Minibatch loss for epoch 53: 0.437237\n",
      "   Avg Minibatch loss for epoch 54: 0.429362\n",
      "   Avg Minibatch loss for epoch 55: 0.423219\n",
      "     ***   Training set accuracy: 92.04% ***\n",
      "     *** Validation set accuracy: 89.84% ***\n",
      "   Avg Minibatch loss for epoch 56: 0.416218\n",
      "   Avg Minibatch loss for epoch 57: 0.410606\n",
      "   Avg Minibatch loss for epoch 58: 0.405824\n",
      "   Avg Minibatch loss for epoch 59: 0.401467\n",
      "   Avg Minibatch loss for epoch 60: 0.397463\n",
      "     ***   Training set accuracy: 92.61% ***\n",
      "     *** Validation set accuracy: 90.10% ***\n",
      "   Avg Minibatch loss for epoch 61: 0.393777\n",
      "   Avg Minibatch loss for epoch 62: 0.389397\n",
      "   Avg Minibatch loss for epoch 63: 0.386264\n",
      "   Avg Minibatch loss for epoch 64: 0.385771\n",
      "   Avg Minibatch loss for epoch 65: 0.380696\n",
      "     ***   Training set accuracy: 92.65% ***\n",
      "     *** Validation set accuracy: 90.21% ***\n",
      "   Avg Minibatch loss for epoch 66: 0.377677\n",
      "   Avg Minibatch loss for epoch 67: 0.376424\n",
      "   Avg Minibatch loss for epoch 68: 0.373577\n",
      "   Avg Minibatch loss for epoch 69: 0.373227\n",
      "   Avg Minibatch loss for epoch 70: 0.370995\n",
      "     ***   Training set accuracy: 93.11% ***\n",
      "     *** Validation set accuracy: 90.32% ***\n",
      "   Avg Minibatch loss for epoch 71: 0.367327\n",
      "   Avg Minibatch loss for epoch 72: 0.366995\n",
      "   Avg Minibatch loss for epoch 73: 0.366943\n",
      "   Avg Minibatch loss for epoch 74: 0.361942\n",
      "   Avg Minibatch loss for epoch 75: 0.363503\n",
      "     ***   Training set accuracy: 93.07% ***\n",
      "     *** Validation set accuracy: 90.36% ***\n",
      "   Avg Minibatch loss for epoch 76: 0.361413\n",
      "   Avg Minibatch loss for epoch 77: 0.359674\n",
      "   Avg Minibatch loss for epoch 78: 0.359032\n",
      "   Avg Minibatch loss for epoch 79: 0.358324\n",
      "   Avg Minibatch loss for epoch 80: 0.357856\n",
      "     ***   Training set accuracy: 93.43% ***\n",
      "     *** Validation set accuracy: 90.58% ***\n",
      "   Avg Minibatch loss for epoch 81: 0.355954\n",
      "   Avg Minibatch loss for epoch 82: 0.352835\n",
      "   Avg Minibatch loss for epoch 83: 0.354081\n",
      "   Avg Minibatch loss for epoch 84: 0.354888\n",
      "   Avg Minibatch loss for epoch 85: 0.353340\n",
      "     ***   Training set accuracy: 93.49% ***\n",
      "     *** Validation set accuracy: 90.48% ***\n",
      "   Avg Minibatch loss for epoch 86: 0.353199\n",
      "   Avg Minibatch loss for epoch 87: 0.351321\n",
      "   Avg Minibatch loss for epoch 88: 0.350501\n",
      "   Avg Minibatch loss for epoch 89: 0.349001\n",
      "   Avg Minibatch loss for epoch 90: 0.348999\n",
      "     ***   Training set accuracy: 93.72% ***\n",
      "     *** Validation set accuracy: 90.71% ***\n",
      "   Avg Minibatch loss for epoch 91: 0.348505\n",
      "   Avg Minibatch loss for epoch 92: 0.344754\n",
      "   Avg Minibatch loss for epoch 93: 0.347187\n",
      "   Avg Minibatch loss for epoch 94: 0.347855\n",
      "   Avg Minibatch loss for epoch 95: 0.345286\n",
      "     ***   Training set accuracy: 93.85% ***\n",
      "     *** Validation set accuracy: 90.83% ***\n",
      "   Avg Minibatch loss for epoch 96: 0.344618\n",
      "   Avg Minibatch loss for epoch 97: 0.345603\n",
      "   Avg Minibatch loss for epoch 98: 0.342528\n",
      "   Avg Minibatch loss for epoch 99: 0.342243\n",
      "   Avg Minibatch loss for epoch 100: 0.343318\n",
      "     ***   Training set accuracy: 93.89% ***\n",
      "     *** Validation set accuracy: 90.64% ***\n",
      "   Avg Minibatch loss for epoch 101: 0.342689\n",
      "   Avg Minibatch loss for epoch 102: 0.342735\n",
      "   Avg Minibatch loss for epoch 103: 0.342745\n",
      "   Avg Minibatch loss for epoch 104: 0.339571\n",
      "   Avg Minibatch loss for epoch 105: 0.342238\n",
      "     ***   Training set accuracy: 93.92% ***\n",
      "     *** Validation set accuracy: 90.75% ***\n",
      "   Avg Minibatch loss for epoch 106: 0.341100\n",
      "   Avg Minibatch loss for epoch 107: 0.340130\n",
      "   Avg Minibatch loss for epoch 108: 0.339880\n",
      "   Avg Minibatch loss for epoch 109: 0.337687\n",
      "   Avg Minibatch loss for epoch 110: 0.338341\n",
      "     ***   Training set accuracy: 94.15% ***\n",
      "     *** Validation set accuracy: 90.65% ***\n",
      "   Avg Minibatch loss for epoch 111: 0.339065\n",
      "   Avg Minibatch loss for epoch 112: 0.338970\n",
      "   Avg Minibatch loss for epoch 113: 0.337416\n",
      "   Avg Minibatch loss for epoch 114: 0.336854\n",
      "   Avg Minibatch loss for epoch 115: 0.336727\n",
      "     ***   Training set accuracy: 94.19% ***\n",
      "     *** Validation set accuracy: 90.82% ***\n",
      "   Avg Minibatch loss for epoch 116: 0.336560\n",
      "   Avg Minibatch loss for epoch 117: 0.337580\n",
      "   Avg Minibatch loss for epoch 118: 0.337137\n",
      "   Avg Minibatch loss for epoch 119: 0.336309\n",
      "   Avg Minibatch loss for epoch 120: 0.334328\n",
      "     ***   Training set accuracy: 94.11% ***\n",
      "     *** Validation set accuracy: 90.55% ***\n",
      "   Avg Minibatch loss for epoch 121: 0.335611\n",
      "   Avg Minibatch loss for epoch 122: 0.334879\n",
      "   Avg Minibatch loss for epoch 123: 0.334028\n",
      "   Avg Minibatch loss for epoch 124: 0.334433\n",
      "\n",
      "   Final Training set accuracy: 94.29%\n",
      "   Final Validation set accuracy: 90.82%\n",
      "   Test set accuracy: 96.21%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "num_epochs = 125\n",
    "h0 = 256\n",
    "h1 = 256\n",
    "h2 = 256\n",
    "lambda_ = 5e-5\n",
    "lr = .0005\n",
    "keep_prob = .675\n",
    "\n",
    "run_sizes = [500, 1000, 2500, 5000, 10000, 25000, 50000, 250000, 100000, train_labels.shape[0]]\n",
    "\n",
    "lcurves = []\n",
    "\n",
    "for m in run_sizes:\n",
    "    x_train_dataset = train_dataset[:m, :]\n",
    "    x_train_labels = train_labels[:m, :]\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data. For the training data, we use a placeholder that will be fed\n",
    "        # at run time with a training minibatch.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "        tf_tr_dataset = tf.constant(x_train_dataset)\n",
    "\n",
    "        # Variables.\n",
    "        w0 = tf.Variable(tf.truncated_normal([image_size * image_size, h0]))\n",
    "        b0 = tf.Variable(tf.zeros([h0]))\n",
    "\n",
    "        w1 = tf.Variable(tf.truncated_normal([h0, h1]))\n",
    "        b1 = tf.Variable(tf.zeros([h1]))\n",
    "\n",
    "        w2 = tf.Variable(tf.truncated_normal([h1, h2]))\n",
    "        b2 = tf.Variable(tf.zeros([h2]))\n",
    "\n",
    "        w3 = tf.Variable(tf.truncated_normal([h2, num_labels]))\n",
    "        b3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "        # Training computation.\n",
    "        s0 = tf.nn.dropout(tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0), keep_prob)\n",
    "        s1 = tf.nn.dropout(tf.nn.relu(tf.matmul(s0, w1) + b1), keep_prob)\n",
    "        s2 = tf.nn.relu(tf.matmul(s1, w2) + b2)\n",
    "        logits = tf.matmul(s2, w3) + b3\n",
    "\n",
    "        reg = tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3)\n",
    "        # reg = tf.reduce_sum(tf.square(w0)) + tf.reduce_sum(tf.square(w1)) + tf.reduce_sum(tf.square(w1))\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + (lambda_ * reg)\n",
    "\n",
    "        # Optimizer.\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "        # Predictions for the training, validation, and test data.\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "        v0 = tf.nn.relu(tf.matmul(tf_valid_dataset, w0) + b0)\n",
    "        v1 = tf.nn.relu(tf.matmul(v0, w1) + b1)\n",
    "        v2 = tf.nn.relu(tf.matmul(v1, w2) + b2)\n",
    "        valid_prediction = tf.nn.softmax(tf.matmul(v2, w3) + b3)\n",
    "\n",
    "        t0 = tf.nn.relu(tf.matmul(tf_test_dataset, w0) + b0)\n",
    "        t1 = tf.nn.relu(tf.matmul(t0, w1) + b1)\n",
    "        t2 = tf.nn.relu(tf.matmul(t1, w2) + b2)\n",
    "        test_prediction = tf.nn.softmax(tf.matmul(t2, w3) + b3)\n",
    "\n",
    "        r0 = tf.nn.relu(tf.matmul(tf_tr_dataset, w0) + b0)\n",
    "        r1 = tf.nn.relu(tf.matmul(r0, w1) + b1)\n",
    "        r2 = tf.nn.relu(tf.matmul(r1, w2) + b2)\n",
    "        tr_prediction = tf.nn.softmax(tf.matmul(r2, w3) + b3)\n",
    "\n",
    "    batches = np.ceil(float(train_labels.shape[0]) / batch_size)\n",
    "    num_steps = int(np.ceil(float(train_labels.shape[0]) / batch_size))\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Run size %d initialized\" % m)\n",
    "        for epoch in range(num_epochs):\n",
    "            l_mean = 0\n",
    "            for step in range(num_steps):\n",
    "                # Pick an offset within the training data, which has been randomized.\n",
    "                # Note: we could use better randomization across epochs.\n",
    "                # offset = (step * batch_size) % (int(batch_size * 2.5) - batch_size)\n",
    "                offset = (step * batch_size) % (x_train_labels.shape[0] - batch_size)\n",
    "                # Generate a minibatch.\n",
    "                batch_data = x_train_dataset[offset:(offset + batch_size), :]\n",
    "                batch_labels = x_train_labels[offset:(offset + batch_size), :]\n",
    "                # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "                # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "                # and the value is the numpy array to feed to it.\n",
    "                feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "\n",
    "                _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "                l_mean += l\n",
    "\n",
    "            print(\"   Avg Minibatch loss for epoch %d: %f\" % (epoch, l_mean / num_steps))\n",
    "            # print(\" Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            if (epoch % 5 == 0):\n",
    "                tra = accuracy(tr_prediction.eval(), x_train_labels)\n",
    "                va = accuracy(valid_prediction.eval(), valid_labels)\n",
    "                print(\"     ***   Training set accuracy: %.2f%% ***\" % tra)\n",
    "                print(\"     *** Validation set accuracy: %.2f%% ***\" % va)\n",
    "\n",
    "        ta = accuracy(tr_prediction.eval(), x_train_labels)\n",
    "        va = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        lcurves.append({\"m\": m, \"train\": 1 - ta / 100, \"val\": 1 - va / 100})\n",
    "        print(\"\\n   Final Training set accuracy: %.2f%%\" % ta)\n",
    "        print(\"   Final Validation set accuracy: %.2f%%\" % va)\n",
    "        print(\"   Test set accuracy: %.2f%%\\n\\n\" % accuracy(test_prediction.eval(), test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        m     train     val\n",
      "0     500  0.000000  0.2131\n",
      "1    1000  0.001000  0.2061\n",
      "2    2500  0.002800  0.1971\n",
      "3    5000  0.001800  0.1706\n",
      "4   10000  0.002100  0.1531\n",
      "5   25000  0.003400  0.1343\n",
      "6   50000  0.007100  0.1204\n",
      "7  250000  0.060545  0.0951\n",
      "8  100000  0.027610  0.1043\n",
      "9  200000  0.057140  0.0918\n"
     ]
    }
   ],
   "source": [
    "lc = pd.DataFrame(lcurves)\n",
    "print(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
