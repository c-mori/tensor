{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def rmse(predictions, actual):\n",
    "    sse = np.sum(np.square(predictions - actual))\n",
    "    return np.sqrt(sse / float(actual.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "hidden = n * 7\n",
    "\n",
    "# Generate training data and outputs\n",
    "train_x = np.random.normal(size=(200000, n))\n",
    "\n",
    "mults = np.arange(n) + 1\n",
    "bias = -3\n",
    "\n",
    "train_y = np.dot(train_x, mults) + bias\n",
    "train_y = np.expand_dims(train_y.astype(np.float32), 1)\n",
    "\n",
    "# add some noise to X\n",
    "# train_x = (9 * train_x + np.random.normal(size=train_x.shape)) / 10\n",
    "train_x = train_x.astype(np.float32)\n",
    "\n",
    "# Training parameters:\n",
    "batch_size = 75\n",
    "epochs = 40\n",
    "\n",
    "keep_percentage = .5\n",
    "learn_rate = 1e-4\n",
    "lambda_ = 0\n",
    "\n",
    "num_labels = train_y.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, n), name='X')\n",
    "    tf_train_labels = tf.placeholder(\n",
    "        tf.float32, shape=(None, num_labels), name='y')\n",
    "    tf_keep_prob = tf.placeholder(tf.float32, name='keep_rate')\n",
    "\n",
    "    # Variables.\n",
    "    # w0 = tf.Variable(tf.truncated_normal([n, hidden]), name='w0')\n",
    "    w0 = tf.get_variable(\"w0\", shape=[n, hidden], \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b0 = tf.Variable(tf.zeros([hidden]), name='b0')\n",
    "    # w1 = tf.Variable(tf.truncated_normal([hidden, num_labels]), name='w1')\n",
    "    w1 = tf.get_variable(\"w1\", shape=[hidden, num_labels], \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.zeros([num_labels]), name='b1')\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.nn.relu(tf.matmul(tf_train_dataset, w0) + b0)\n",
    "    logits = tf.nn.dropout(logits, tf_keep_prob)\n",
    "    logits = tf.matmul(logits, w1) + b1\n",
    "    loss = (tf.reduce_sum(tf.square(logits - tf_train_labels)) +\n",
    "            lambda_ * (tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1)))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(loss)\n",
    "\n",
    "    # Predictions\n",
    "    train_prediction = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 106667 batches (40 epochs)\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4686.233887\n",
      "Minibatch RMSE: 7.90463\n",
      "Train set RMSE: 8.09281\n",
      "Minibatch loss at step 2667: 1294.767090\n",
      "Minibatch RMSE: 4.15494\n",
      "Train set RMSE: 3.88924\n",
      "Minibatch loss at step 5334: 291.934509\n",
      "Minibatch RMSE: 1.97293\n",
      "Train set RMSE: 0.99860\n",
      "Minibatch loss at step 8001: 288.561096\n",
      "Minibatch RMSE: 1.96150\n",
      "Train set RMSE: 0.72456\n",
      "Minibatch loss at step 10668: 302.234863\n",
      "Minibatch RMSE: 2.00744\n",
      "Train set RMSE: 0.59763\n",
      "Minibatch loss at step 13335: 291.658234\n",
      "Minibatch RMSE: 1.97200\n",
      "Train set RMSE: 0.46803\n",
      "Minibatch loss at step 16002: 239.817383\n",
      "Minibatch RMSE: 1.78817\n",
      "Train set RMSE: 0.45399\n",
      "Minibatch loss at step 18669: 314.759369\n",
      "Minibatch RMSE: 2.04861\n",
      "Train set RMSE: 0.40423\n",
      "Minibatch loss at step 21336: 279.103363\n",
      "Minibatch RMSE: 1.92909\n",
      "Train set RMSE: 0.37961\n",
      "Minibatch loss at step 24003: 262.615173\n",
      "Minibatch RMSE: 1.87124\n",
      "Train set RMSE: 0.42816\n",
      "Minibatch loss at step 26670: 133.084610\n",
      "Minibatch RMSE: 1.33209\n",
      "Train set RMSE: 0.42585\n",
      "Minibatch loss at step 29337: 211.284592\n",
      "Minibatch RMSE: 1.67843\n",
      "Train set RMSE: 0.38783\n",
      "Minibatch loss at step 32004: 317.243225\n",
      "Minibatch RMSE: 2.05667\n",
      "Train set RMSE: 0.40071\n",
      "Minibatch loss at step 34671: 405.910461\n",
      "Minibatch RMSE: 2.32640\n",
      "Train set RMSE: 0.40955\n",
      "Minibatch loss at step 37338: 142.533340\n",
      "Minibatch RMSE: 1.37857\n",
      "Train set RMSE: 0.42988\n",
      "Minibatch loss at step 40005: 172.961319\n",
      "Minibatch RMSE: 1.51860\n",
      "Train set RMSE: 0.41972\n",
      "Minibatch loss at step 42672: 285.643463\n",
      "Minibatch RMSE: 1.95156\n",
      "Train set RMSE: 0.41192\n",
      "Minibatch loss at step 45339: 212.591843\n",
      "Minibatch RMSE: 1.68361\n",
      "Train set RMSE: 0.37562\n",
      "Minibatch loss at step 48006: 245.410080\n",
      "Minibatch RMSE: 1.80890\n",
      "Train set RMSE: 0.39559\n",
      "Minibatch loss at step 50673: 296.445587\n",
      "Minibatch RMSE: 1.98812\n",
      "Train set RMSE: 0.39037\n",
      "Minibatch loss at step 53340: 130.523071\n",
      "Minibatch RMSE: 1.31921\n",
      "Train set RMSE: 0.43361\n",
      "Minibatch loss at step 56007: 231.049805\n",
      "Minibatch RMSE: 1.75518\n",
      "Train set RMSE: 0.38968\n",
      "Minibatch loss at step 58674: 308.737671\n",
      "Minibatch RMSE: 2.02892\n",
      "Train set RMSE: 0.41710\n",
      "Minibatch loss at step 61341: 230.203964\n",
      "Minibatch RMSE: 1.75197\n",
      "Train set RMSE: 0.42046\n",
      "Minibatch loss at step 64008: 189.617203\n",
      "Minibatch RMSE: 1.59004\n",
      "Train set RMSE: 0.39692\n",
      "Minibatch loss at step 66675: 195.596191\n",
      "Minibatch RMSE: 1.61491\n",
      "Train set RMSE: 0.38064\n",
      "Minibatch loss at step 69342: 418.374756\n",
      "Minibatch RMSE: 2.36185\n",
      "Train set RMSE: 0.40659\n",
      "Minibatch loss at step 72009: 311.379761\n",
      "Minibatch RMSE: 2.03758\n",
      "Train set RMSE: 0.42643\n",
      "Minibatch loss at step 74676: 215.115143\n",
      "Minibatch RMSE: 1.69358\n",
      "Train set RMSE: 0.41873\n",
      "Minibatch loss at step 77343: 169.490906\n",
      "Minibatch RMSE: 1.50329\n",
      "Train set RMSE: 0.41820\n",
      "Minibatch loss at step 80010: 229.136597\n",
      "Minibatch RMSE: 1.74790\n",
      "Train set RMSE: 0.38756\n",
      "Minibatch loss at step 82677: 336.136383\n",
      "Minibatch RMSE: 2.11703\n",
      "Train set RMSE: 0.41422\n",
      "Minibatch loss at step 85344: 319.301483\n",
      "Minibatch RMSE: 2.06334\n",
      "Train set RMSE: 0.41955\n",
      "Minibatch loss at step 88011: 182.114380\n",
      "Minibatch RMSE: 1.55827\n",
      "Train set RMSE: 0.40272\n",
      "Minibatch loss at step 90678: 178.683273\n",
      "Minibatch RMSE: 1.54352\n",
      "Train set RMSE: 0.39442\n",
      "Minibatch loss at step 93345: 298.286163\n",
      "Minibatch RMSE: 1.99428\n",
      "Train set RMSE: 0.37017\n",
      "Minibatch loss at step 96012: 201.327728\n",
      "Minibatch RMSE: 1.63840\n",
      "Train set RMSE: 0.42471\n",
      "Minibatch loss at step 98679: 193.393082\n",
      "Minibatch RMSE: 1.60579\n",
      "Train set RMSE: 0.39619\n",
      "Minibatch loss at step 101346: 209.769562\n",
      "Minibatch RMSE: 1.67240\n",
      "Train set RMSE: 0.38654\n",
      "Minibatch loss at step 104013: 246.649399\n",
      "Minibatch RMSE: 1.81347\n",
      "Train set RMSE: 0.40529\n",
      "\n",
      "actual y values:\n",
      "[[ -7.56832981]\n",
      " [ -1.33163941]\n",
      " [  3.14401817]\n",
      " ..., \n",
      " [-11.88003731]\n",
      " [ -2.25134635]\n",
      " [  1.4393369 ]]\n",
      "\n",
      " predictions:\n",
      "[[ -7.34539604]\n",
      " [ -1.3719852 ]\n",
      " [  2.83209109]\n",
      " ..., \n",
      " [-11.46367073]\n",
      " [ -2.25329113]\n",
      " [  1.22962165]]\n",
      "\n",
      " Total time: 1.933 minutes\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCV8EZESoYQvIlIilPBFRErE/wEFIZx+/9mM2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c802d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "num_steps = int(np.ceil(epochs * float(train_y.shape[0]) / batch_size))\n",
    "print(\"Running %d batches (%d epochs)\" % (num_steps, epochs))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_x[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_y[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {\n",
    "            tf_train_dataset: batch_data,\n",
    "            tf_train_labels: batch_labels,\n",
    "            tf_keep_prob: keep_percentage}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % int(np.ceil(float(train_y.shape[0]) / batch_size)) == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch RMSE: %.5f\" % rmse(predictions, batch_labels))\n",
    "\n",
    "            print(\"Train set RMSE: %.5f\" % rmse(logits.eval(\n",
    "                feed_dict={tf_train_dataset: train_x, tf_keep_prob: 1.0}), train_y))\n",
    "    print(\"\")\n",
    "    feed_dict = {\n",
    "        tf_train_dataset: train_x,\n",
    "        tf_keep_prob: 1.0}\n",
    "    preds = logits.eval(feed_dict=feed_dict)\n",
    "    # print preds\n",
    "\n",
    "print(\"actual y values:\")\n",
    "print(train_y)\n",
    "print(\"\\n predictions:\")\n",
    "print(preds)\n",
    "\n",
    "print(\"\\n Total time: %.3f minutes\") % ((time.time() - start) / 60.)\n",
    "\n",
    "plt.scatter(train_y.reshape([-1, 1]), preds.reshape([-1, 1]))\n",
    "plt.plot([train_y.min(), train_y.max()], [\n",
    "         train_y.min(), train_y.max()], 'k-', lw=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [avx]",
   "language": "python",
   "name": "Python [avx]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}